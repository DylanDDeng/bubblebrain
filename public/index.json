[{"content":"Kuaishou recently refreshed its New Coding Model lineup with two releases: KAT-Coder-Pro V1 and KAT-Coder-Air V1.\nBoth variants integrate smoothly with leading coding-agent tools such as Claude Code, Cline, and Kilo.\nI ran the Pro model inside Claude Code, and the onboarding experience was straightforward.\nBelow is the Claude Code configuration I used:\nexport ANTHROPIC_BASE_URL=\u0026#34;https://wanqing.streamlakeapi.com/api/gateway/v1/endpoints/ep-xxx-xxx/claude-code-proxy\u0026#34; export ANTHROPIC_AUTH_TOKEN=\u0026#34;YOUR_WANQING_API_KEY\u0026#34; export ANTHROPIC_MODEL=\u0026#34;KAT-Coder\u0026#34; export ANTHROPIC_SMALL_FAST_MODEL=\u0026#34;KAT-Coder-Air-V1\u0026#34; API keys are available via the Kuaishou Wanqing console.\nFor a quick benchmark, I reran my usual SVG generation test (the Xbox controller graphic). Output quality is still behind other models, so there is room for improvement.\n","permalink":"http://localhost:1314/notes/newcodingmodelfromkuaishou/","summary":"\u003cp\u003eKuaishou recently refreshed its New Coding Model lineup with two releases: \u003cstrong\u003eKAT-Coder-Pro V1\u003c/strong\u003e and \u003cstrong\u003eKAT-Coder-Air V1\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eBoth variants integrate smoothly with leading coding-agent tools such as Claude Code, Cline, and Kilo.\u003c/p\u003e","title":"New Coding Model from Kuaishou","type":"post"},{"content":"这是一个专门用于测试移动端适配效果的页面。\n标题测试 三级标题 四级标题 段落测试 这是一个包含中文内容的段落，用于测试在移动设备上的显示效果。这段文字足够长，可以测试换行和阅读体验。中文内容在移动端需要特别注意字间距和行间距的设置。\n这里是另一个段落，包含了粗体文字和斜体文字的测试，还有链接测试。\n列表测试 无序列表 这是一个列表项，内容比较长，用于测试在移动端的显示效果 另一个列表项 嵌套列表项 另一个嵌套项 最后一个列表项 有序列表 第一个有序列表项，内容较长用于测试 第二个有序列表项 嵌套的有序列表 另一个嵌套项 最后一个有序列表项 引用测试 这是一个引用块，包含了较长的中文内容，用于测试在移动设备上的显示效果和换行情况。引用的样式需要确保在较小的屏幕上仍然保持良好的可读性。\n代码测试 行内代码 这是一个包含 console.log(\u0026quot;Hello World\u0026quot;) 行内代码的句子。\n代码块 function testMobile() { const message = \u0026#34;这是一个用于测试移动端显示的代码块\u0026#34;; console.log(message); // 长代码行测试 const veryLongVariableName = \u0026#34;这是一个超长的字符串，用于测试代码块在移动端的横向滚动效果\u0026#34;; return message; } 表格测试 列1标题 列2标题 列3标题 普通内容 这个内容比较长 短内容 另一个长内容测试 中等长度 这是一个非常长的内容，用于测试表格在移动端的显示效果 最后行 测试完成 ✅ 图片测试 长链接测试 这是一个超长的URL链接测试：https://bubblebrain.me/posts/这是一个超长的中文路径测试页面用于验证移动端适配效果\n数学公式测试 这是一个行内公式：$E = mc^2$\n结论 这个测试页面包含了常见的Markdown元素，用于验证移动端适配效果。请在不同的移动设备上查看此页面，检查以下方面：\n✅ 内容是否正确换行，没有水平滚动条 ✅ 字体大小是否合适，易于阅读 ✅ 表格和代码块是否可以横向滚动 ✅ 图片是否正确缩放 ✅ 长链接是否正确处理换行 ✅ 目录在移动端的显示效果 如有任何问题，请记录具体的设备和浏览器信息。\n","permalink":"http://localhost:1314/test-mobile/","summary":"\u003cp\u003e这是一个专门用于测试移动端适配效果的页面。\u003c/p\u003e\n\u003ch2 id=\"标题测试\"\u003e标题测试\u003c/h2\u003e\n\u003ch3 id=\"三级标题\"\u003e三级标题\u003c/h3\u003e\n\u003ch4 id=\"四级标题\"\u003e四级标题\u003c/h4\u003e\n\u003ch2 id=\"段落测试\"\u003e段落测试\u003c/h2\u003e\n\u003cp\u003e这是一个包含中文内容的段落，用于测试在移动设备上的显示效果。这段文字足够长，可以测试换行和阅读体验。中文内容在移动端需要特别注意字间距和行间距的设置。\u003c/p\u003e\n\u003cp\u003e这里是另一个段落，包含了\u003cstrong\u003e粗体文字\u003c/strong\u003e和\u003cem\u003e斜体文字\u003c/em\u003e的测试，还有\u003ca href=\"https://bubblebrain.me\"\u003e链接测试\u003c/a\u003e。\u003c/p\u003e\n\u003ch2 id=\"列表测试\"\u003e列表测试\u003c/h2\u003e\n\u003ch3 id=\"无序列表\"\u003e无序列表\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e这是一个列表项，内容比较长，用于测试在移动端的显示效果\u003c/li\u003e\n\u003cli\u003e另一个列表项\n\u003cul\u003e\n\u003cli\u003e嵌套列表项\u003c/li\u003e\n\u003cli\u003e另一个嵌套项\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e最后一个列表项\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"有序列表\"\u003e有序列表\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e第一个有序列表项，内容较长用于测试\u003c/li\u003e\n\u003cli\u003e第二个有序列表项\n\u003col\u003e\n\u003cli\u003e嵌套的有序列表\u003c/li\u003e\n\u003cli\u003e另一个嵌套项\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e最后一个有序列表项\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"引用测试\"\u003e引用测试\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这是一个引用块，包含了较长的中文内容，用于测试在移动设备上的显示效果和换行情况。引用的样式需要确保在较小的屏幕上仍然保持良好的可读性。\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"代码测试\"\u003e代码测试\u003c/h2\u003e\n\u003ch3 id=\"行内代码\"\u003e行内代码\u003c/h3\u003e\n\u003cp\u003e这是一个包含 \u003ccode\u003econsole.log(\u0026quot;Hello World\u0026quot;)\u003c/code\u003e 行内代码的句子。\u003c/p\u003e\n\u003ch3 id=\"代码块\"\u003e代码块\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-javascript\" data-lang=\"javascript\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003efunction\u003c/span\u003e \u003cspan class=\"nx\"\u003etestMobile\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kr\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003emessage\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;这是一个用于测试移动端显示的代码块\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nx\"\u003econsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003elog\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003emessage\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 长代码行测试\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kr\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003everyLongVariableName\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;这是一个超长的字符串，用于测试代码块在移动端的横向滚动效果\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"nx\"\u003emessage\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"表格测试\"\u003e表格测试\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e列1标题\u003c/th\u003e\n          \u003cth\u003e列2标题\u003c/th\u003e\n          \u003cth\u003e列3标题\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e普通内容\u003c/td\u003e\n          \u003ctd\u003e这个内容比较长\u003c/td\u003e\n          \u003ctd\u003e短内容\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e另一个长内容测试\u003c/td\u003e\n          \u003ctd\u003e中等长度\u003c/td\u003e\n          \u003ctd\u003e这是一个非常长的内容，用于测试表格在移动端的显示效果\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e最后行\u003c/td\u003e\n          \u003ctd\u003e测试完成\u003c/td\u003e\n          \u003ctd\u003e✅\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"图片测试\"\u003e图片测试\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"测试图片\" loading=\"lazy\" src=\"https://via.placeholder.com/800x400\" title=\"测试图片\"\u003e\u003c/p\u003e","title":"移动端测试页面","type":"post"},{"content":"最近在代码生成方面发现 Codex 真的很好用！\n特别是对于一些重复性的模板代码，Codex 能快速生成基础结构，然后我只需要做微调就可以了。\n# 比如生成一个简单的 Flask 路由 @app.route(\u0026#39;/api/data\u0026#39;) def get_data(): return jsonify({\u0026#34;message\u0026#34;: \u0026#34;Hello from Codex!\u0026#34;}) 效率提升很明显，特别是处理一些我不太熟悉的语言或者框架时。\n","permalink":"http://localhost:1314/notes/%E6%9C%80%E8%BF%91%E5%A5%BD%E7%94%A8%E7%9A%84ai%E5%B7%A5%E5%85%B7%E6%98%AFcodex/","summary":"\u003cp\u003e最近在代码生成方面发现 Codex 真的很好用！\u003c/p\u003e\n\u003cp\u003e特别是对于一些重复性的模板代码，Codex 能快速生成基础结构，然后我只需要做微调就可以了。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 比如生成一个简单的 Flask 路由\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nd\"\u003e@app.route\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;/api/data\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eget_data\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejsonify\u003c/span\u003e\u003cspan class=\"p\"\u003e({\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;message\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Hello from Codex!\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e})\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e效率提升很明显，特别是处理一些我不太熟悉的语言或者框架时。\u003c/p\u003e","title":"最近好用的AI工具是codex","type":"post"},{"content":"最近发现排版设计真的很有魔力！尝试了各种字体组合、间距调整和色彩搭配，感觉整个公众号的气质都提升了不少。\n特别喜欢简约风格的排版，留白足够，阅读起来特别舒服。还在学习如何更好地运用图标和分割线来提升视觉效果。\n","permalink":"http://localhost:1314/notes/%E6%9C%80%E8%BF%91%E7%96%AF%E7%8B%82%E6%B2%89%E8%BF%B7%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%8E%92%E7%89%88/","summary":"\u003cp\u003e最近发现排版设计真的很有魔力！尝试了各种字体组合、间距调整和色彩搭配，感觉整个公众号的气质都提升了不少。\u003c/p\u003e\n\u003cp\u003e特别喜欢简约风格的排版，留白足够，阅读起来特别舒服。还在学习如何更好地运用图标和分割线来提升视觉效果。\u003c/p\u003e","title":"最近疯狂沉迷于公众号排版","type":"post"},{"content":"昨天 Sam Altman 与他的 OpenAI 团队参加了 Reddit 上的 AMA 直播，来回答网友们任何关于 GPT-5 的问题。\nAMA 即 Ask Me Anything。一般都是回答网友的各种问题\n原贴地址：GPT-5 AMA with OpenAI’s Sam Altman and some of the GPT-5 team\n我随手整理了一版，方便大家阅读。\n关于老模型 Sam Altman 表示已经收到了大量关于恢复 GPT-4o 的反馈，表示会重新为 Plus 用户启用它，并会观察使用情况，以确定支持多长时间 对于 GPT-4.1， Sam Altman 表示团队正在探索用户是否同时需要 4o 和 4.1 或者仅仅有4o 就足够 关于 GPT-4.5， 团队没有正面回应，但是也说了认为 GPT-5-Thinking 能带来更好，更有趣的写作能力。 发布会的错误与技术修复 对于发布会 PPT 的图表错误，Sam Altman 表示直播之前加班搞到太晚，太累了，出现了人为错误。但是博客文章以及系统卡里的介绍都是准确的。 GPT-5 在发布时出现了严重的技术问题，自动切换器也坏了。这导致对于很多用户的查询没有找到正确的模型，所以表现异常的迟钝。团队正在对决策边界进行干预，帮助用户更频繁地获得正确的模型，并且考虑增加模型回答的透明度，以便让用户更好地知道是哪个模型回答的问题。 GPT-5 的重大发布导致 API 流量在 24 小时内翻倍，导致了很多用户的服务出现了中断。OpenAI 预计会在一两天内让服务稳定，并将 Plus 用户的速率限制翻倍，以完成最后的推广。 OpenAI 承诺自动切换器会更好用。当然，也可以通过在 prompt 里加入指令，比如 “Think Hard” 来让模型强制触发思考推理模式。 关于编程以及工具调用 Codex CLI 现在通过付费的 ChatGPT 计划来支持 GPT-5. Pro 用户几乎不会遇到用量上的限制， Plus 和 Team 用户每周可以处理几个 1-2 小时的对话，并且速率限制会每 5 小时重置，按周的维度来统计。 Codex CLI 很快将迎来重大升级 已经在考虑将 GitHUb 直接集成到 ChatGPT 中，这样可以让 ChatGPT 直接读取代码仓库 GPT-5 工具调用能力明显增强，特别是 GPT-5-Thinking 版本。 未来考虑会把 GPT-5-Pro 集成到 API 中，但是会非常贵 。 关于产品 新推出的聊天气泡颜色的定制功能是开放给所有用户 未来会考虑在 IDE 中让ChatGPT 以第三方插件的方式兼容进来。 关于模型与未来计划 之前传的很火的 Zenith 和 Summit，团队经过大量的测试以及评估，最终 Summit 在排行榜和内部测试中大幅优于 Zenith。 团队认为 GPT-5 相比于之前的 GPT-4 在很多方面都有重大的提升：推理、写作、指令遵循等。 考虑增加 Plus 用户的上下文长度，目前仅有 32K，非常的有限。 对于 GPT-5， 有一个遗憾是没能做大支持更长的上下文。研究人员 Michelle Pokrass 表示，如果计算资源、成本都允许的情况下，更愿意支持 1M 的上下文长度 与 Opus 4.1 的比较，OpenAI 认为两个都是非常好的模型。对于别家的模型，不能评价很多，但是它们认为 GPT-5 是它们发布过写代码最好的模型。 它们正在努力将推理和非推理模型统一为一个单一模型，并且考虑采用 Token 定价的方式而不是消息限制。 ChatGPT 的 memory 功能即将迎来升级。 GPT-5 在长文对话方面已经取得了进步 昨天新发的语音模型在指令遵循、响应都有很大的提升。同时，OpenAI 表示目前没有相关计划做一个数字人在语音模式中。（像 Grok 那样） ","permalink":"http://localhost:1314/posts/openai-%E6%9C%80%E6%96%B0%E5%9B%9E%E5%BA%94%E6%9C%89%E5%85%B3-gpt-5/","summary":"\u003cp\u003e昨天 Sam Altman 与他的 OpenAI 团队参加了 Reddit 上的 AMA 直播，来回答网友们任何关于 \u003cstrong\u003eGPT-5\u003c/strong\u003e 的问题。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAMA 即 Ask Me Anything。一般都是回答网友的各种问题\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e原贴地址：\u003c/strong\u003e\u003ca href=\"https://www.reddit.com/r/ChatGPT/comments/1mkae1l/gpt5_ama_with_openais_sam_altman_and_some_of_the/\"\u003eGPT-5 AMA with OpenAI’s Sam Altman and some of the GPT-5 team\u003c/a\u003e\u003c/p\u003e","title":"OpenAI 最新回应有关 GPT-5","type":"post"},{"content":"朋友们，大家好。\n今天给大家带来 Anthropic 的 CEO，Dario Amodei 最近参加的一次采访内容的整理，他不仅分享了 Anthropic 飞速发展的秘密，更是对当前 AI 领域的诸多争议给出了自己的见解。\nDario Amodei 以及它背后的 Anthropic 公司一直以来颇具争议。一方面在编码领域，Claude 天下第一，不得不服；另一方面，Dario 本人以及 Anthropic 对中国以及中国用户持有显而易见的偏见，哪怕是海外用户，也对它们的模型限量策略怨声载道。 以及非常神奇的是Dario 本人早年还在百度呆过一年。\n言归正传，不管 Anthropic 对用户到底是一个什么样的态度，这个公司的一些研究论文、访谈都是值得观看学习的。\n访谈链接： https://www.youtube.com/watch?v=mYDSSRS-B5U\n不愿被称为“悲观主义”的AI领导者 首先，Dario 对那些称他为“AI 悲观主义”的人感到非常愤怒。他表示自己绝非想减缓 AI 的发展。恰恰相反，他深知这项技术带来的益处，甚至能够拯救生命。如果技术早日加速实现，他的父亲也不会当年因病离世。\nDario 强调外界对他的很多批评是错误的，比如批评他想掌控、垄断整个 AI 行业\nDario 认为他自己以及 Anthropic 在阐述 AI 带来的好处方面甚至比一些盲目的“乐观主义者”做的更好。正是因为他们甚至 AI 能创造一个多么美好的世界，他才感到有义务去警示 AI 可能带来的风险，以此来督促人们把事情做对。\n他强烈批评了那些不理解 AI 带来的好处、只知道“加速发展”的加速主义者，认为它们缺乏道德公信力。\nAI 的指数级发展与 Dario 的“短时间线” Dario 认为整个AI领域最真实且核心的现象是指数级增长。也就是大家经常会看到的每隔几个月，新的 AI 模型会比前一个效果好很多，而这得益于对计算资源、数据投入和新型训练犯法的持续投资。\n他观察到，AI 系统正在从几年前的“勉强能用”发展到“聪明的高中生”，现在正接近“聪明的大学生”甚至是“博士生”的水平，并开始在整个经济领域发挥作用。\n尽管 Dario 认为预测未来是非常困难的一件事，特别是关于社会层面，但是对于底层技术的进步、发展，他非常的自信。他提到，虽然有 20-25% 的可能性模型在未来两年内停止提升，但鉴于他所看到的增长趋势，他愿意承担这种风险。\nDario 解释说，人们不太能理解指数级增长：一个每六个月翻一番的事物，在它真正爆发的两年前，看起来只完成了$\\frac{1}{16}$。因此，我们现在可能正处于 AI 能力和收入的“爆炸式增长”的边缘。他将这比作 90 年代互联网的崛起，当时很少有人预见到它会以多快的速度带来全球数字通信网络。\nAnthropic 如何应对行业质疑 面对行业中的各种质疑，Dario 逐一进行了回应：\n关于“回报递减”的担忧： 他表示，至少在 Anthropic 的模型中，它们并未看到任何回报递减的迹象。以编码为例，Anthropic 的模型在短时间内取得了显著进步，每次发布新版本，其编码能力都大幅度提升，Benchmark 成绩和实际使用量都呈指数级增长。他也透露，Anthropic 内部大多数代码的编写都与他们的 Claude 模型有关，其他公司也有类似的情况。\n大模型缺乏“持续学习”的弱点？ Dario 认为，即使这个问题永远无法完全解决，LLM 影响整个经济的潜力依然非常高。他打了个比方，即使一位诺贝尔奖获得者无法学习新的知识，但如果有一千万个这样的人，他们仍然能带来大量的生物学突破。(也就是说，即使模型本身有学习与记忆上的限制，规模化与能力本身仍然能带来很强的实际效果。)\nAnthropic 资源不足无，无法与科技巨头竞争？ Dario 表示，Anthropic 已经筹集了近 200 亿美元的资金，这并非小数目。他强调，Anthropic 在数据中心建设方面的规模，与其他任何公司相比，都不算小。而且，Anthropic 的核心竞争力在于人才密度。他自豪地表示，Anthropic 的人才流失率很低，许多人拒绝了其他公司的巨额报价，因为他们真正相信 Anthropic 的使命。他认为一些公司的“高价挖人”策略是试图“购买无法购买的东西”，即对使命的认同。 他还指出，Anthropic 是历史上发展最快的软件公司之一，从创立到现在每年都实现10 倍增长 。 他认为这种增长速度足以证明它们与大公司竞争的能力。\n开源模型是威胁？ Dario 认为，将开源视为威胁，本质上是一种障眼法。他解释说，AI 领域的“开源”通常指“开放权重”，与传统软件的“开源代码”不同，你无法看到模型内部的运行机制。他指出，竞争的关键还是在于模型本身是否足够好，能否在特定的任务上胜过对手，而不是在于它是否开源。因为最终，即使是开源模型也需要在云端托管并进行推理，而这也需要巨大的计算资源和优化能力，并非免费。\nAnthropic 的商业模式与增长哲学 Anthropic 的商业模式有其独特之处：\n聚焦 B 端市场 Dario 表示，Anthropic 的主要赌注在于模型在商业场景中的应用，而非单出的 API 或消费级产品。虽然目前大部分收入来自 API，但是它们也有快速增长的应用业务。他认为，AI 的企业级应用甚至会比消费级应用更广阔。他距离说明，将一个模型的生化能力从本科生提升到博士生水平，对普通消费者可能意义不大，但对辉瑞这样的公司，价值可能提升 10 倍。他相信，专注于商业用例，能更好地激励它们开发出更智能，更能解决现实问题的模型， 比如在生物医学、地缘政治、经济发展、金融、法律和生产力等领域。\n编码是关键切入点 最初，Anthropic 只是想让模型在多个方面变得更好，但编码作为一种应用，其价值特别突出。许多工程师发现他们的模型终于能完成它们以前做不到的事情。而且提升模型的编码能力，反过来能帮他们开发出下一代模型，具有双重优势。\n盈利的假象 Dario 解释，外界认为 Anthropic “亏损严重”的看法是有些误导的。他区分了两个概念：\n运行现有模型的成本 他表示，运行模型的成本实际上是“相当盈利的”。推理效率一直在大幅提升，导致给定智能水平的价格不断下降。\n训练下一代模型的成本 公司之所以看起来不盈利，是因为每年都投入巨资来训练更强大、更先进的模型。他用一个类比解释：一个模型可能投入一亿美元训练，次年带来了 2 亿美元收入（利润为 1 亿美元），但公司整体因为持续的、巨大的研发投入而看起来“亏损”。他预计，两年后模型成本可能与现在差不多，但其能力、自主性和应用范围都将大大提升，创造的价值也会飙升。\nAI 治理：非零和博弈与“竞相向上” Dario 在访谈中也谈到了当年离开 OpenAI 的原因，并非技术本身，而是公司层面的决策、治理以及领导“真诚度”问题。他认为，AI 系统的安全性和能力是相互交织的，而如何在组织层面做出正确的决策至关重要。\n驳斥控制论 对于外界批评他“想要控制整个行业，只有他能构建安全 AI”的言论，Dario 表示这是非常皇庙的谎言。他强调 Anthropic 的目标是推动一场竞相向上的运动，而不是竞相向下的运动。两者的区别在于，在竞相向下的模式中，每个人都急于尽快推出产品，导致不安全的系统出现，所有人都会输。而在竞相向上中，无论谁赢，最后所有人都会赢。 Anthropic 通过以下方式树立榜样：\n率先发布负责任的扩展政策，鼓励其他公司效仿。 开放可解释性研究，甚至为此牺牲潜在的商业优势 推行宪法式 AI 等安全技术 衡量并公开 AI 系统的危险能力评估。他认为，通过这些行动，它们旨在为整个领域树立榜样，而不是垄断技术。 Dario 认为 AI 领域存在着两种非常极端的观点，并且这两种观点在智力上和道德上都不严肃。\n“悲观主义者”：他认为那些声称“不可能构建安全的 AI”的人是完全胡说八道。他承认 AI 存在危险，并且对人类整体构成危险，但断言无法使其安全是 “无稽之谈”。他强调，随着每一代模型的发布，它们在控制模型方面都取得了进步。\n加速主义者/坐拥万亿美元资本的人：Dario同样批评那些只看到“美元符号”，鼓吹十年内无需监管技术的人。他认为将安全担忧归结为“想要控制技术”的指控是“离谱且在道德上不严肃的”。他认为，当前形势要求我们更加深思熟虑，更加诚实并且投入更多研究，以理解和应对 AI 的巨大风险与益处。他自己每天都在思考这些问题，并且亲身经历过 AI 能拯救生命（比如他父亲的例子），也亲眼看到过模型的负面行为（如 Grok 的例子）。他呼吁行业内有更多人愿意这样做，不惧挑战，为理解现状增添光明和洞察力。\n一些思索 一直有句老话，大概意思是说不要看一个人说了什么，要看一个人做了什么。尽管Dario一再声称自己并不是搞掌控、垄断，但是从他之前发文公开抨击 DeepSeek，再到切断 Windsurf、OpenAI 的 claude API 供应，以及对国内用户使用 Claude 的围剿封杀，其实很难相信他采访中说的是它真实的内心想法。\n但是另一方面，又不得不佩服Anthropic这个公司产出的东西是真的牛逼。无论是凭借 claude 模型独一无二的编码能力带起了 Vibe Coding 的狂热浪潮，再到 Claude Code 的推出，彻底改变了原先 AI 编程的交互形态，以及 Anthropic 每项研究论文、博客几乎都是经典中的经典。\n这可能也给大家做产品带来一些思路：要么做的市场足够下沉，要么做的天下第一，让所有人一边骂你但是又不得不用你的东西。\n","permalink":"http://localhost:1314/posts/dario-amodei%E8%AE%BF%E8%B0%88%E6%95%B4%E7%90%86/","summary":"\u003cp\u003e朋友们，大家好。\u003c/p\u003e\n\u003cp\u003e今天给大家带来 Anthropic 的 CEO，\u003cstrong\u003eDario Amodei\u003c/strong\u003e 最近参加的一次采访内容的整理，他不仅分享了 Anthropic 飞速发展的秘密，更是对当前 AI 领域的诸多争议给出了自己的见解。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDario Amodei 以及它背后的 Anthropic 公司一直以来颇具争议。一方面在编码领域，Claude 天下第一，不得不服；另一方面，Dario 本人以及 Anthropic 对中国以及中国用户持有显而易见的偏见，哪怕是海外用户，也对它们的模型限量策略怨声载道。 以及非常神奇的是Dario 本人早年还在百度呆过一年。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e言归正传，不管 Anthropic 对用户到底是一个什么样的态度，这个公司的一些研究论文、访谈都是值得观看学习的。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e访谈链接： \u003ca href=\"https://www.youtube.com/watch?v=mYDSSRS-B5U\"\u003ehttps://www.youtube.com/watch?v=mYDSSRS-B5U\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://raw.githubusercontent.com/DylanDDeng/image/main/CleanShot%202025-08-04%20at%2012.09.33%402x.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"不愿被称为悲观主义的ai领导者\"\u003e不愿被称为“悲观主义”的AI领导者\u003c/h3\u003e\n\u003cp\u003e首先，Dario 对那些称他为“AI 悲观主义”的人感到非常愤怒。他表示自己绝非想减缓 AI 的发展。恰恰相反，他深知这项技术带来的益处，甚至能够拯救生命。如果技术早日加速实现，他的父亲也不会当年因病离世。\u003c/p\u003e","title":"Dario Amodei 访谈整理","type":"post"},{"content":"最近压力很大，工作上出现了一些问题，以及忙着搬家。\n这趟搬家大概持续了两个月，直到这两天才逐渐搬完，搞定。我们找了一套开发商新装修好的房子，但是里面的柜子什么的都是没有的，需要我们自己弄。房东委托中介给我们安排了全屋定制。\n但是这个做定制的设计师反正弄的也是一团糟，尺寸量的很多地方有问题，然后有的设计的地方也不符合我们的要求。反正来来回回装柜子、修、补，这些都做了一个月了，然后还有布置新家，以及我们自己搬家。整体是一个非常疲惫的过程，真的搬一次家感觉半条命都没了。我女朋友在这其中做了大量的工作，真的很不容易，特别是跟装柜子的人扯皮扯来扯去，都是她弄的。以我这种，“嫌烦，懒得管”、“不是自己的家，搞那么好”的这种心态，肯定是没法把这件事做的很好的。\n如果说搬家、装修这些事早晚都会结束，还有些盼头，工作上出的这个问题，真的是在我的意料之外了。\n4 月份，我女朋友因为我的引荐，入职了我现在在的公司，和我一个部门。但是直到前两周 Q2 季度结束，谈话的时候，我曾经最信任的领导给我的口径都是虽然不是很满意，但是都愿意再给机会试试。结果过了不到一周，就被通知解雇了，连试用期都没满，甚至 3 个月的时间都不到。而且是非常临时的通知，甚至一点心理准备都没有。下午通知的，当天就是 last day。\n事情反正大致就是这样，但是其中细节，发生的种种令人恶心的事远不止这么简单。\n我也并不能改变什么，但是这也给我上了非常深刻的一课。职场上哪怕和你关系再好的人，都不值得你信任。以及无论在哪里上班，都是给别人打工，在我熟悉的工作环境中，都碰上了这样的事情，更不要说陌生的工作环境了。这也由此激发了我自己创业的想法。\n自己创业做的想法来源于两个方面：\n对现状的不满意。我觉得我包括我所在的部门现在的工作是有问题的。从来没有好好的打磨过一款产品，每次都是只做成一个 demo，然后就不接着往下做了。一共就 10 个人左右的团队，却做了好多的 demo，但是一款像样的产品都没有。而在我看来，如果只是做 demo 的话，我一个人就可以做现在这个团队里的人做的东西，我认为它们做的都很烂。 发生在我女朋友身上的事，同样也给我上了一课。当初，想把她引荐进来，主要就是觉得这边相对稳定，然后部门领导也是认识的，相对比较熟悉点，不像在别的公司，逼事很多。结果没想到，才三个月不到，也发生了这样的事。如果连我这里都这样，更不要说其他公司了。所以企业、团队本质都是一样的，不是自己的团队，跟你关系再好，也都是假的。那与其这样，我不如自己干，反正我觉得我现在团队做的东西都很烂，我自己也能做。 反正事情虽然很糟心，但是也都发生了，改变不了什么。日子还要继续，希望会好起来。\n碎碎念结束～\n","permalink":"http://localhost:1314/posts/%E4%B8%80%E4%BA%9B%E9%9A%8F%E7%AC%94/","summary":"\u003cp\u003e最近压力很大，工作上出现了一些问题，以及忙着搬家。\u003c/p\u003e\n\u003cp\u003e这趟搬家大概持续了两个月，直到这两天才逐渐搬完，搞定。我们找了一套开发商新装修好的房子，但是里面的柜子什么的都是没有的，需要我们自己弄。房东委托中介给我们安排了全屋定制。\u003c/p\u003e\n\u003cp\u003e但是这个做定制的设计师反正弄的也是一团糟，尺寸量的很多地方有问题，然后有的设计的地方也不符合我们的要求。反正来来回回装柜子、修、补，这些都做了一个月了，然后还有布置新家，以及我们自己搬家。整体是一个非常疲惫的过程，真的搬一次家感觉半条命都没了。我女朋友在这其中做了大量的工作，真的很不容易，特别是跟装柜子的人扯皮扯来扯去，都是她弄的。以我这种，“嫌烦，懒得管”、“不是自己的家，搞那么好”的这种心态，肯定是没法把这件事做的很好的。\u003c/p\u003e\n\u003cp\u003e如果说搬家、装修这些事早晚都会结束，还有些盼头，工作上出的这个问题，真的是在我的意料之外了。\u003c/p\u003e\n\u003cp\u003e4 月份，我女朋友因为我的引荐，入职了我现在在的公司，和我一个部门。但是直到前两周 Q2 季度结束，谈话的时候，我曾经最信任的领导给我的口径都是虽然不是很满意，但是都愿意再给机会试试。结果过了不到一周，就被通知解雇了，连试用期都没满，甚至 3 个月的时间都不到。而且是非常临时的通知，甚至一点心理准备都没有。下午通知的，当天就是 last day。\u003c/p\u003e\n\u003cp\u003e事情反正大致就是这样，但是其中细节，发生的种种令人恶心的事远不止这么简单。\u003c/p\u003e\n\u003cp\u003e我也并不能改变什么，但是这也给我上了非常深刻的一课。职场上哪怕和你关系再好的人，都不值得你信任。以及无论在哪里上班，都是给别人打工，在我熟悉的工作环境中，都碰上了这样的事情，更不要说陌生的工作环境了。这也由此激发了我自己创业的想法。\u003c/p\u003e\n\u003cp\u003e自己创业做的想法来源于两个方面：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e对现状的不满意。我觉得我包括我所在的部门现在的工作是有问题的。从来没有好好的打磨过一款产品，每次都是只做成一个 demo，然后就不接着往下做了。一共就 10 个人左右的团队，却做了好多的 demo，但是一款像样的产品都没有。而在我看来，如果只是做 demo 的话，我一个人就可以做现在这个团队里的人做的东西，我认为它们做的都很烂。\u003c/li\u003e\n\u003cli\u003e发生在我女朋友身上的事，同样也给我上了一课。当初，想把她引荐进来，主要就是觉得这边相对稳定，然后部门领导也是认识的，相对比较熟悉点，不像在别的公司，逼事很多。结果没想到，才三个月不到，也发生了这样的事。如果连我这里都这样，更不要说其他公司了。所以企业、团队本质都是一样的，不是自己的团队，跟你关系再好，也都是假的。那与其这样，我不如自己干，反正我觉得我现在团队做的东西都很烂，我自己也能做。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e反正事情虽然很糟心，但是也都发生了，改变不了什么。日子还要继续，希望会好起来。\u003c/p\u003e\n\u003cp\u003e碎碎念结束～\u003c/p\u003e","title":"一些随笔","type":"post"},{"content":"朋友们，大家好。\n这两天读到开源的代码 Agent，Cline 团队的一篇博客，《Why Cline Doesn\u0026rsquo;t Index Your Codebase (And Why That\u0026rsquo;s a Good Thing) 》，做了一些整理和探索，来分享一下这篇博客内容。\n先放原文链接：Why Cline Doesn\u0026rsquo;t Index Your Codebase (And Why That\u0026rsquo;s a Good Thing)\n为什么RAG不行？ 早期，在模型上下文窗口还不大的时候，RAG 一直是作为让模型获取到额外相关上下文信息的办法而存在。哪怕到现在，这个市面上大部分的 AI 知识库解决方案也依然是 RAG，因为这种方法非常简单—它将知识库进行分块、创建嵌入、存储到向量数据库中，并在需要时会根据问题进行相关片段的检索。\n但是，代码数据与其他数据不同。它是互相关联且不断演变的。当你将传统的 RAG 方法应用于代码库时，会出现三个关键问题：\n1. 代码不是以块的形式思考 RAG 大致上来说可以分为两个部分：索引知识库（代码库）和检索。但是当你将代码块用于嵌入时，实际上是破坏了原有的代码库逻辑。举个例子来说，假设一个函数被调用是在片段 47，但是它的定义是在片段 892，而解释它存在的关键上下文又可能是散落在其他十几个片段中，先不说模型最后是否能够真正解决问题，就连把这些相关片段一次性全部检索出来，都是十分困难的。因为对于自然语言来说，一般的段落和句子，为创建具有语义意义的片段提供了明显的边界点，但是代码库的构造那就是完全另一回事了，所以简单的分块方法在准确界定代码有意义方面存在许多困难。\n2. 索引随代码演变而衰减 实际上生产环境中，代码库不是静态的，而是一直在不断变化的。所以，索引不是一次性或周期性的工作。每一次你的代码合并都可能导致 AI的理解 与你的代码库之间存在分歧。所以，这也会导致你的代码助手会自信地建议调用不再存在的函数。\n3. 安全 使用 RAG 还有一个最大的问题是安全。当你将你的代码库文件转换为向量嵌入时，你需要将其存储在某个地方。不管是云服务商，还是自己部署托管，都要花费额外的资源去做保证安全。\nCline 的方法 Cline 采用的方法更像一个真实的开发者在处理代码库时一样。它不提供索引或者嵌入。它只是通过遵循代码的自然结构来构建上下文，进行智能探索。\n举例来说，你如果开发一个 React 组件。Cline 读取它，看到导入语句，然后跟随它。那个文件又导入另一个文件，所以 Cline 也跟随了那个文件。每个文件都建立在之前的基础上，从而形成一个相互关联的理解，展示你的代码是如何运作的。\n这种方法其实非常依赖模型的上下文窗口。\n无论是 Claude 4 也好，还是Gemini 2.5 Pro，都提供了非常大的上下文窗口。Cline 的这种像人类工程师一样阅读代码库的方法自然能生成高质量的上下文，因为它遵循的是代码库里的逻辑结构，而不是像 RAG 一样，把代码库文件切块，依赖语义进行匹配。\n示例 原博客里有一个具体的示例来说明 Cline 的方法和 RAG 的不同。\n假如要 AI 给你的项目里的一个“支付处理函数”添加错误处理的逻辑。如果是 RAG 为基础的代码助手可能会在向量索引里找和“payment”，“error”有关的代码片段，然后从中挑几块认为相关的塞进错误处理的逻辑。但是这样做是有问题的，因为你的项目很可能有自己定制的错误处理框架，结果代码助手没有找到它，于是 AI 很可能给你建议在代码里加入一些通用的 try-catch。这和你的项目模式完全不吻合。\nCline 的做法则截然不同：它会真正找到支付函数的源码位置，接着顺着代码找出它 import 的错误处理工具模块，然后再看看这个工具模块是如何实现的，再然后，看看项目里有没有其他类似函数，它们是如何处理错误的，以学习整个项目的代码模式。最后，Cline 基于这一系列的“深入阅读”得来的理解，提出修改方案：新增的错误处理代码正好符合你现有的架构和风格（比如用上了你项目中的错误处理框架，而不是生搬硬套别处的通用代码）。\n性能问题 尽管实际文件搜索在某些场合中可能更慢，\n但是 Cline 团队认为当模型足够强大到能真正理解代码时，瓶颈不是检索速度\u0026ndash;而是上下文质量的比拼。\n而且代码本身已经在本地了，直接让 AI 读取，更加自然，何必多此一举先弄个向量索引副本呢？也许 RAG 是能节省点 Token 调用成本，但是这种方法并不是想要 AI 真正读懂自己的代码。\n既然如此， Cline 团队认为就不应该节省这个成本，应该将智能直接应用于用户的代码库上。\n写在最后 这篇博客其实非常好地阐述了 Cline 作为一个代码助手是如何处理一个庞大的代码库的，也从侧面说明了为什么使用 Cline 这么耗Token。\n同样，越来越多的代码工具也意识到光靠 RAG 这样的静态检索，是不能带来很好的效果的。比如 Claude Code，它也没有事先构建索引以及通过向量嵌入的方式来处理代码。和 Cline 类似，但是又不同的是，它是通过调用工具，然后动态的、根据实际需求来搜索代码文件。\n好啦，本期的分享就先到这儿了～\n大家有机会一定要多去阅读这些知名的开源工具团队或者公司的博客内容，它们实践的经验不仅对我们使用工具有很大的帮助，也同样能加深我们自己对 AI 的理解和认知。\n感谢您读到这里！若觉得内容有帮助，欢迎点赞、在看、关注。别错过更新，给公众号加个星标⭐️吧！期待与您的下次相遇～\n","permalink":"http://localhost:1314/posts/cline-blog/","summary":"\u003cp\u003e朋友们，大家好。\u003c/p\u003e\n\u003cp\u003e这两天读到开源的代码 Agent，Cline 团队的一篇博客，《Why Cline Doesn\u0026rsquo;t Index Your Codebase (And Why That\u0026rsquo;s a Good Thing) 》，做了一些整理和探索，来分享一下这篇博客内容。\u003c/p\u003e\n\u003cp\u003e先放原文链接：\u003ca href=\"https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing\"\u003eWhy Cline Doesn\u0026rsquo;t Index Your Codebase (And Why That\u0026rsquo;s a Good Thing)\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"为什么rag不行\"\u003e为什么RAG不行？\u003c/h2\u003e\n\u003cp\u003e早期，在模型上下文窗口还不大的时候，RAG 一直是作为让模型获取到额外相关上下文信息的办法而存在。哪怕到现在，这个市面上大部分的 AI 知识库解决方案也依然是 RAG，因为这种方法非常简单—它将知识库进行分块、创建嵌入、存储到向量数据库中，并在需要时会根据问题进行相关片段的检索。\u003c/p\u003e","title":"Cline 是如何处理您的代码库的","type":"post"},{"content":"故事的开始是发生在 1 年多前，硅谷发生了令人震惊的杀妻案件。凶手用拳头一拳拳打死了自己的妻子，再加上 华人、高学历、清华、大厂这样的无敌光环，这件案子当时格外引人关注。\n但是随着时间的推移，关注度来的快去的也快，而且再加上天高皇帝远的，毕竟是在美国开的庭，接触到的后续相关信息也很少，大家对这件事的关注度就慢慢散了。\n但是最近，这个案子又终于开审了，很多案件的细节都被曝光了出来。\n作为一个经常需要依靠 AI 才能不在各类繁杂的信息源中不迷失的用户，觉得DeepResearch 真的太适合这类多个资料的搜寻、整合、最后输出了。\n这不，正好 Kimi 的 Researcher来了么～\n我用 Kimi 的 Researcher 对硅谷杀妻案做了一个深度的报告，梳理了整个事件的始末发展。\n首先，Kimi 的深度研究会先根据我的指令进行反问确认，确保自己能进一步理解清楚我的需求。\n与我进一步确认之后，它开始进行搜索工作。\n有意思的是，为了扩大搜索范围，它不仅用不同的中文关键词进行搜索，还同样使用英文关键词进行了搜索。\n和大部分 Agent 不一样的是，Kimi 的 DeepResearch 是调用 Python 来写入一个 Markdown 文件。\n当然，整个执行的过程中，并不是一帆风顺的，Kimi 还是会遇到困难，但是得益于端到端的强化学习训练，它能自己学会找到合适的办法解决问题。\n最终，Kimi 给了我一份 12460 字的报告，详细梳理了案件的始末，以及目前的进度，并且做到了几乎每句话都有迹可循。\n甚至，它还搜到了一些案件的惊人细节，比如第三者：\n以及凶手可能的辩护策略：\n详细报告因为长度关系，就不放在这里了。感兴趣内容的小伙伴可以直接私信我领取查看哦。\n最让我觉得惊艳的是 Kimi 最后给我生成的那份可视化的报告，信息量和美感都非常在线。\n您的浏览器不支持视频标签。 这份可视化报告同样保留了引用源的标注，提高了可信度的同时也方便查询。同时，它还针对一些关键信息（案件凶手和被害人之间的关系节点、整个案件发生的前后时间线等）画了流程图，便于理解。最后它也结合一些搜索到的法律人士的专业意见，给出了案件可能的最终走向，以及给出了一些建议来避免这类悲剧的事情再次发生。\n整个报告的预览链接在这里➡️： https://www.kimi.com/preview/197b74a5-b521-8674-ba47-02a74b00051e\n看完整个报告，从案发到现在，还是难以想象受害者临终前的绝望，一拳一拳被自己曾经最心爱的人打死，被迫离开了这个美好的世界。 那个曾经应该是用来监控小猫进食的摄像头，却意外拍下了这最残忍、惊悚的一幕。\n只希望正义早日到来，杀人凶手能得到应有的惩罚，受害者也能早日安息。\n感谢您读到这里！若觉得内容有帮助，欢迎点赞、在看、关注。别错过更新，给公众号加个星标⭐️吧！期待与您的下次相遇～\n","permalink":"http://localhost:1314/posts/kimi-deepresearch/","summary":"\u003cp\u003e故事的开始是发生在 1 年多前，硅谷发生了令人震惊的杀妻案件。凶手用拳头一拳拳打死了自己的妻子，再加上 \u003cstrong\u003e华人\u003c/strong\u003e、\u003cstrong\u003e高学历\u003c/strong\u003e、\u003cstrong\u003e清华\u003c/strong\u003e、\u003cstrong\u003e大厂\u003c/strong\u003e这样的无敌光环，这件案子当时格外引人关注。\u003c/p\u003e\n\u003cp\u003e但是随着时间的推移，关注度来的快去的也快，而且再加上天高皇帝远的，毕竟是在美国开的庭，接触到的后续相关信息也很少，大家对这件事的关注度就慢慢散了。\u003c/p\u003e\n\u003cp\u003e但是最近，这个案子又终于开审了，很多案件的细节都被曝光了出来。\u003c/p\u003e\n\u003cp\u003e作为一个经常需要依靠 AI 才能不在各类繁杂的信息源中不迷失的用户，觉得DeepResearch 真的太适合这类多个资料的搜寻、整合、最后输出了。\u003c/p\u003e\n\u003cp\u003e这不，正好 Kimi 的 \u003cstrong\u003eResearcher\u003c/strong\u003e来了么～\u003c/p\u003e\n\u003cp\u003e我用 Kimi 的 Researcher 对硅谷杀妻案做了一个深度的报告，梳理了整个事件的始末发展。\u003c/p\u003e\n\u003cp\u003e首先，Kimi 的深度研究会先根据我的指令进行反问确认，确保自己能进一步理解清楚我的需求。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图例 1\" loading=\"lazy\" src=\"https://fastly.jsdelivr.net/gh/bucketio/img2@main/2025/06/29/1751157338999-9bb7109f-a294-42e3-ad00-bf9306fd23d9.png\"\u003e\u003c/p\u003e\n\u003cp\u003e与我进一步确认之后，它开始进行搜索工作。\u003c/p\u003e\n\u003cp\u003e有意思的是，为了扩大搜索范围，它不仅用不同的中文关键词进行搜索，还同样使用英文关键词进行了搜索。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图例 2\" loading=\"lazy\" src=\"https://fastly.jsdelivr.net/gh/bucketio/img14@main/2025/06/29/1751157649690-59a73a1e-edcf-4db3-bc45-8019cf9c0b48.png\"\u003e\u003c/p\u003e\n\u003cp\u003e和大部分 Agent 不一样的是，Kimi 的 DeepResearch 是调用 Python 来写入一个 Markdown 文件。\u003c/p\u003e","title":"用AI深挖硅谷杀妻案，我发现了12460字都写不完的惊人内幕","type":"post"},{"content":"这是一个展示如何在博客文章中嵌入视频的示例。\n1. 本地视频 如果你有一个本地视频文件，可以将它放在本文章的目录下（与index.md同级），然后使用video shortcode：\n您的浏览器不支持视频标签。 2. Bilibili视频 嵌入B站视频非常简单，只需要视频的BV号：\n3. YouTube视频 YouTube视频使用Hugo内置的shortcode：\n4. 带参数的视频 你可以控制视频的各种属性：\n您的浏览器不支持视频标签。 5. 直接使用HTML 如果需要更精细的控制，也可以直接写HTML：\n\u0026lt;video controls width=\u0026#34;100%\u0026#34; style=\u0026#34;border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;/videos/demo.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;\u0026gt; 您的浏览器不支持视频播放。 \u0026lt;/video\u0026gt; 注意事项 视频文件建议压缩到合理大小（\u0026lt;50MB） 使用MP4格式以获得最佳兼容性 对于大文件，考虑使用视频平台或CDN ","permalink":"http://localhost:1314/posts/video-example/","summary":"\u003cp\u003e这是一个展示如何在博客文章中嵌入视频的示例。\u003c/p\u003e\n\u003ch2 id=\"1-本地视频\"\u003e1. 本地视频\u003c/h2\u003e\n\u003cp\u003e如果你有一个本地视频文件，可以将它放在本文章的目录下（与index.md同级），然后使用video shortcode：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-markdown\" data-lang=\"markdown\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\n\n\n\n\n\n\n\n\u003cvideo \n  controls\n  \n  \n  \n  width=\"100%\" \n  height=\"auto\"\n  style=\"max-width: 100%; height: auto;\"\u003e\n  \u003csource src=\"demo.mp4\" type=\"video/mp4\"\u003e\n  您的浏览器不支持视频标签。\n\u003c/video\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"2-bilibili视频\"\u003e2. Bilibili视频\u003c/h2\u003e\n\u003cp\u003e嵌入B站视频非常简单，只需要视频的BV号：\u003c/p\u003e\n\n\n\n\n\n\n\u003cdiv class=\"video-container\" style=\"position: relative; width: 100%; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n  \u003ciframe \n    src=\"//player.bilibili.com/player.html?bvid=BV1xx411c7mD\u0026page=1\u0026autoplay=0\" \n    scrolling=\"no\" \n    border=\"0\" \n    frameborder=\"no\" \n    framespacing=\"0\" \n    allowfullscreen=\"true\"\n    style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\"\u003e\n  \u003c/iframe\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"3-youtube视频\"\u003e3. YouTube视频\u003c/h2\u003e\n\u003cp\u003eYouTube视频使用Hugo内置的shortcode：\u003c/p\u003e","title":"视频嵌入示例","type":"post"},{"content":" 本文为 Langchain 官方博客“The rise of context engineering”的双语对照版本。 推荐阅读理由：随着 Agent 的快速发展，”context“ 的概念越来越被重视。无论是 Vibe Coding，还是 Deep Research，提供的 ”context“越具体完整，最后出来的效果都会很棒！LangGraph 作为最著名的智能体框架之一，了解它们是如何看待上下文的重要性的，无论是对我们个人平时 AI 的使用还是企业业务上 AI 的落地，都有很大帮助。\nHeader image from Dex Horthy on Twitter\n来自 Dex Horthy 的 Twitter 头图\nContext engineering is building dynamic systems to provide the right information and tools in the right format such that the LLM can plausibly accomplish the task.\n上下文工程是构建动态系统，以在正确的格式中提供正确的信息和工具，使得 LLM 能够合理地完成任务。\nMost of the time when an agent is not performing reliably the underlying cause is that the appropriate context, instructions and tools have not been communicated to the model.\n大多数情况下，当智能体（agent) 表现不稳定时，根本原因是合适恰当的上下文、指令和工具没有传达给模型。\nLLM applications are evolving from single prompts to more complex, dynamic agentic systems. As such, context engineering is becoming the most important skill an AI engineer can develop.\nLLM 应用正从单一提示发展到更复杂、动态的智能体系统。因此，上下文工程成为 AI 工程师可以发展的最重要技能。\nWhat is context engineering? 什么是上下文工程？\nContext engineering is building dynamic systems to provide the right information and tools in the right format such that the LLM can plausibly accomplish the task.\n上下文工程是构建动态系统，以在正确的格式中提供正确的信息和工具，使得 LLM 能够合理地完成任务。\nThis is the definition that I like, which builds upon recent takes on this from Tobi Lutke, Ankur Goyal, and Walden Yan. Let’s break it down.\n这是我喜欢的定义，它基于 Tobi Lutke、Ankur Goyal 和 Walden Yan 最近对此的见解。让我们来分解一下。\nContext engineering is a system\n上下文工程是一个系统\nComplex agents likely get context from many sources. Context can come from the developer of the application, the user, previous interactions, tool calls, or other external data. Pulling these all together involves a complex system.\n复杂的智能体很可能从多个来源获取上下文。上下文可以来自应用程序的开发者、用户、之前的交互、工具调用或其他外部数据。将这些内容整合起来需要一个复杂的系统。\nThis system is dynamic 这个系统是动态的\nMany of these pieces of context can come in dynamically. As such, the logic for constructing the final prompt needs to be dynamic as well. It is not just a static prompt.\n这些上下文中的许多部分是动态变化的。因此，构建最终提示的逻辑也需要是动态的。它不仅仅是一个静态的提示。\nYou need the right information\n你需要正确的信息\nA common reason agentic systems don’t perform is they just don’t have the right context. LLMs cannot read minds - you need to give them the right information. Garbage in, garbage out.\n一个常见的原因是智能体系统表现不佳，因为它们只是缺乏正确的上下文。LLMs 无法读心术——你需要提供正确的信息。不然，垃圾进，垃圾出。\nYou need the right tools\n你需要正确的工具\nIt may not always be the case that the LLM will be able to solve the task just based solely on the inputs. In these situations, if you want to empower the LLM to do so, you will want to make sure that it has the right tools. These could be tools to look up more information, take actions, or anything in between. Giving the LLM the right tools is just as important as giving it the right information.\n并不总是 LLM 仅凭输入就能完成任务的情况。在这些情况下，如果你想要赋予 LLM 这样的能力，你需要确保它拥有正确的工具。这些工具可以是用来查找更多信息、执行操作或介于两者之间的任何东西。给 LLM 提供正确的工具与提供正确的信息同样重要。\nThe format matters 格式很重要\nJust like communicating with humans, how you communicate with LLMs matters. A short but descriptive error message will go a lot further a large JSON blob. This also applies to tools. What the input parameters to your tools are matters a lot when making sure that LLMs can use them.和与人类交流一样，你与 LLMs 的沟通方式很重要。一条简短但描述性强的报错信息比一大块 JSON 数据要有效得多。这也适用于工具。在确保 LLMs 能够使用它们时，你工具的输入参数是什么非常重要。\nCan it plausibly accomplish the task?\n它能否合理地完成任务？\nThis is a great question to be asking as you think about context engineering. It reinforces that LLMs are not mind readers - you need to set them up for success. It also helps separate the failure modes. Is it failing because you haven’t given it the right information or tools? Or does it have all the right information and it just messed up? These failure modes have very different ways to fix them.\n当你思考上下文工程时，这是一个很好的问题。它强化了 LLMs 不是心灵感应器的观点——你需要为它们创造成功的机会。它还有助于区分失败的原因。是因为你没有给它提供正确的信息或工具而失败？还是它已经有了所有正确的信息，只是出了错？这些失败的原因有非常不同的解决方法。\nWhy is context engineering important？ 为什么上下文工程很重要\nWhen agentic systems mess up, it’s largely because an LLM messes. Thinking from first principles, LLMs can mess up for two reasons:\n当智能体系统出问题时，这主要是因为 LLM 出了问题。从第一性原理出发，LLM 出问题的原因有两个：\nThe underlying model just messed up, it isn’t good enough\n底层模型本身出了问题，它不够好\nThe underlying model was not passed the appropriate context to make a good output\n底层模型没有接收到能够生成良好输出的合适上下文\nMore often than not (especially as the models get better) model mistakes are caused more by the second reason. The context passed to the model may be bad for a few reasons:\n通常情况下（尤其是随着模型性能的提升），模型错误更多是由第二个原因造成的。传递给模型的上下文可能存在问题的原因有：\nThere is just missing context that the model would need to make the right decision. Models are not mind readers. If you do not give them the right context, they won’t know it exists.\n模型需要缺失的上下文才能做出正确决策。模型不会读心术。如果你不提供正确的上下文，它们将不知道其存在。\nThe context is formatted poorly. Just like humans, communication is important! How you format data when passing into a model absolutely affects how it responds\n上下文格式不佳。就像人类一样，沟通很重要！向模型传递数据时的格式化方式会直接影响其响应效果。\nHow is context engineering different from prompt engineering? 上下文工程与提示工程有何不同？\nWhy the shift from “prompts” to “context”? Early on, developers focused on phrasing prompts cleverly to coax better answers. But as applications grow more complex, it’s becoming clear that\nproviding complete and structured context to the AI is far more important than any magic wording.\n为什么从“提示”转向“上下文”？早期，开发者专注于巧妙地措辞提示以获取更好的答案。但随着应用变得更加复杂，提供完整且结构化的上下文给 AI 变得比任何魔法措辞都更为重要。\nI would also argue that prompt engineering is a subset of context engineering. Even if you have all the context, how you assemble it in the prompt still absolutely matters. The difference is that you are not architecting your prompt to work well with a single set of input data, but rather to take a set of dynamic data and format it properly.\n我还认为，提示工程是上下文工程的一个子集。即使你拥有所有上下文，如何在提示中组织它仍然至关重要。区别在于，你不是设计提示以适应单一的数据输入集，而是要处理动态数据并正确地格式化它。\nI would also highlight that a key part of context is often core instructions for how the LLM should behave. This is often a key part of prompt engineering. Would you say that providing clear and detailed instructions for how the agent should behave is context engineering or prompt engineering? I think it’s a bit of both.\n我还要强调的是，上下文信息中一个关键部分往往是关于 LLM 应该如何行动的核心指令。这通常是提示工程的关键部分。你会说为智能体如何行动提供清晰详细的指令是上下文工程还是提示工程？我认为两者都有点涉及。\nExamples of context engineering 上下文工程的示例\nSome basic examples of good context engineering include:\n一些良好的上下文工程的示例包括：\nTool use: Making sure that if an agent needs access to external information, it has tools that can access it. When tools return information, they are formatted in a way that is maximally digestable for LLMs\n工具使用：确保如果智能体需要访问外部信息，它有可以访问这些信息的工具。当工具返回信息时，它们以对 LLMs 最大程度可消化格式进行格式化\nShort term memory: If a conversation is going on for a while, creating a summary of the conversation and using that in the future.\n短期记忆：如果对话持续了一段时间，创建对话摘要并在未来使用该摘要。\nLong term memory: If a user has expressed preferences in a previous conversation, being able to fetch that information.\n长期记忆：如果用户在之前的对话中表达过偏好，能够获取这些信息。\nPrompt Engineering: Instructions for how an agent should behave are clearly enumerated in the prompt.\n提示工程：智能体应如何采取行动的具体指令在提示中明确列出。\nRetrieval: Fetching information dynamically and inserting it into the prompt before calling the LLM.\n检索：动态获取信息并将其插入提示中，然后再调用 LLM。\nHow LangGraph enables context engineering LangGraph如何实现上下文工程\nWhen we built LangGraph, we built it with the goal of making it the most controllable agent framework. This also allows it to perfectly enable context engineering.\n当我们构建 LangGraph 时，我们的目标是将其打造成最可控的智能体框架。这也使其能够完美实现上下文工程。\nWith LangGraph, you can control everything. You decide what steps are run. You decide exactly what goes into your LLM. You decide where you store the outputs. You control everything.\n使用 LangGraph，你可以控制一切。你决定哪些步骤运行。你决定确切的内容输入到你的 LLM。你决定输出存储在哪里。你控制一切。\nThis allows you do all the context engineering you desire. One of the downsides of agent abstractions (which most other agent frameworks emphasize) is that they restrict context engineering. There may be places where you cannot change exactly what goes into the LLM, or exactly what steps are run beforehand.\n这让你能够完成所有你想要的上下文工程。智能体抽象（大多数其他代理框架强调的）的一个缺点是它们限制了上下文工程。可能存在一些地方，你无法改变输入到 LLM 的确切内容，或者无法确定在运行之前执行的确切步骤。\nSide note: a very good read is Dex Horthy\u0026rsquo;s \u0026ldquo;12 Factor Agents\u0026rdquo;. A lot of the points there relate to context engineering (\u0026ldquo;own your prompts\u0026rdquo;, \u0026ldquo;own your context building\u0026rdquo;, etc). The header image for this blog is also taken from Dex. We really enjoy the way he communicates about what is important in the space.\n侧注：Dex Horthy 的《12 Factor Agents》是一本非常值得一读的书。书中的很多观点都与上下文工程相关（如\u0026quot;拥有你的提示\u0026quot;、\u0026ldquo;拥有你的上下文构建\u0026quot;等）。这篇博客的标题图片也来自 Dex。我们非常欣赏他阐述这个领域重要性的方式。\nHow LangSmith helps with context engineering LangSmith 如何助力上下文工程\nLangSmith is our LLM application observability and evals solution. One of the key features in LangSmith is the ability to trace your agent calls. Although the term \u0026ldquo;context engineering\u0026rdquo; didn\u0026rsquo;t exist when we built LangSmith, it aptly describes what this tracing helps with.\nLangSmith 是我们的 LLM 应用可观测性和评估解决方案。LangSmith 的一个关键功能是能够追踪你的智能体调用。虽然我们在构建 LangSmith 时“上下文工程”这个术语还不存在，但它恰当地描述了这项追踪功能所帮助的内容。\nLangSmith lets you see all the steps that happen in your agent. This lets you see what steps were run to gather the data that was sent into the LLM.\nLangSmith 让你能够看到你的智能体中发生的所有步骤。这让你可以看到为了收集发送到 LLM 的数据而运行了哪些步骤。\nLangSmith lets you see the exact inputs and outputs to the LLM. This lets you see exactly what went into the LLM - the data it had and how it was formatted. You can then debug whether that contains all the relevant information that is needed for the task. This includes what tools the LLM has access to - so you can debug whether it\u0026rsquo;s been given the appropriate tools to help with the task at hand.\nLangSmith 让你能够看到 LLM 的确切输入和输出。这让你能够清楚地了解输入到 LLM 的内容——它所使用的数据以及数据的格式。然后你可以调试这些输入是否包含了完成任务所需的所有相关信息。这包括 LLM 可以访问哪些工具——这样你就可以调试它是否被赋予了适当的工具来帮助完成当前的任务。\nCommunication is all you need 沟通就是你需要的全部\nA few months ago I wrote a blog called \u0026ldquo;Communication is all you need\u0026rdquo;. The main point was that communicating to the LLM is hard, and not appreciated enough, and often the root cause of a lot of agent errors. Many of these points have to do with context engineering!\n几个月前我写了一篇名为《沟通是你所需要的全部》的博客。主要观点是，与 LLM 沟通很困难，没有得到足够的重视，并且往往是许多智能体运行错误的根本原因。其中许多观点都与上下文工程有关！\nContext engineering isn\u0026rsquo;t a new idea - agent builders have been doing it for the past year or two. It\u0026rsquo;s a new term that aptly describes an increasingly important skill. We\u0026rsquo;ll be writing and sharing more on this topic. We think a lot of the tools we\u0026rsquo;ve built (LangGraph, LangSmith) are perfectly built to enable context engineering, and so we\u0026rsquo;re excited to see the emphasis on this take off.\n上下文工程并非新概念——过去一两年里，智能体开发者一直在实践它。这是一个恰如其分描述日益重要技能的新术语。我们将就这一主题撰写和分享更多内容。我们认为我们构建的工具（LangGraph、LangSmith）非常适合支持上下文工程，因此我们很兴奋地看到这一领域的重视程度正在提升。\n","permalink":"http://localhost:1314/posts/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E7%9A%84%E5%85%B4%E8%B5%B7/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文为 Langchain 官方博客“The rise of context engineering”的双语对照版本。\n\u003c/br\u003e\n推荐阅读理由：随着 Agent 的快速发展，”context“ 的概念越来越被重视。无论是 Vibe Coding，还是 Deep Research，提供的 ”context“越具体完整，最后出来的效果都会很棒！LangGraph 作为最著名的智能体框架之一，了解它们是如何看待上下文的重要性的，无论是对我们个人平时 AI 的使用还是企业业务上 AI 的落地，都有很大帮助。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"图例\" loading=\"lazy\" src=\"https://raw.githubusercontent.com/DylanDDeng/image/main/image.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eHeader image from  \u003ca href=\"https://x.com/dexhorthy/status/1933283008863482067?ref=blog.langchain.com\"\u003eDex Horthy on Twitter\u003c/a\u003e\u003c/strong\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e来自 Dex Horthy 的 Twitter 头图\u003c/p\u003e","title":"上下文工程的兴起","type":"post"},{"content":"Anthropic 前两天发了一篇文章，重点讨论了他们是如何通过多智能体系统来构建 claude 的“深度研究功能”。\n文章链接： https://www.anthropic.com/engineering/built-multi-agent-research-system\n我仔细研究了一下，觉得写的非常不错，所以写了这篇文章来细致解读一下到底该如何构建一个多智能体系统。\n开始前，我觉得首先要理解两个概念，智能体（Agent）和工作流（Workflow）。\n现阶段我们谈论的智能体绝大多数都是以大模型为核心，利用各种工具自主规划并完成任务执行 工作流指的是按照既定的顺序执行的一系列相互关联的任务。 当我们把智能体放入工作流中，也就有了智能体工作流，也就是大家一直以来听到的 Agentic Workflow。\n传统的工作流，其实比较的死板。就好像写程序一样，运转到哪个节点，做什么操作，都是提前设置好的。而相比于传统的工作流，这种智能体工作流更加灵活，自主。 在这个工作流中，智能体通常能够结合环境，自主的判断下一步执行什么动作，并且能够将复杂的任务拆解为多个可执行的小任务。\n有了这些基本的概念，我们就可以来了解一下 Anthropic 是如何构建自己的多智能体研究系统。\n架构设计 Anthropic 设计的整个研究系统采用了典型的多智能体架构，一个主智能体 + 多个子智能体。这种架构借鉴了调度者-执行者模型（orchestrator-worker pattern）：就好像团队领导和他手底下的员工一样，领导负责总体规划和协调，按需要将一个活派给多个手底下的员工并行执行具体操作。\n具体的架构图如下所示：\n用户在 claude 聊天界面提出需要查询的问题，系统接收到用户请求后，会通过一个主智能体（Lead Agent）来处理任务。Lead Agent 相当于总负责人，具备使用各种工具的能力（如网络搜索工具、内部 MCP 接口工具、内存Memory等等）。Lead Agent 首先对问题进行分析和规划，然后派出多个子智能体（Subagent）并行进行工作，每个 Subagent 负责一个分支的搜索任务。Lead Agent 同时还需要与右侧的记忆模块（Memory）进行交互，这个模块用于在上下文超长时保存重要信息。\n此外，还有一个专门负责处理引用的智能体（Citation Agent），它主要负责在最终报告中添加引用标注。\n整个过程中，Lead Agent 通过任务描述与Subagent 通信，当 Subagent 完成任务后将结果返回给 Lead Agent，最终由 Lead Agent 整合所有 Subagent 的结果撰写出研究报告，然后交给 Citation Agent 插入文献来源标注，形成含引用的最终报告返回给用户。\n下面这张流程图展示的过程更加详细：\nLead Agent 在接收到用户请求后，进入迭代研究流程（图中的浅绿色区域）：它会先通过思考（think）来制定计划方案（plan approach），并将这个计划通过 Memory 模块进行存储（save plan）。这样做是为了应对超长的对话场景，如果后续对话长度超过了模型的上下文限制，计划内容可能就会被截断丢失，所以提前进行存储，有需要时可以进行上下文的检索。\n接着，Lead Agent 会根据制定好的计划来创建多个 Subagent。如图中所示，每个 Subagent 负责不同维度的调查搜索。每个 Subagent 启动后，会进入各自的搜索循环，它们会使用web_search等工具执行搜索，然后将搜索结果进行评估。Subagent 可能会进行反复多轮的搜索和评估，直到完成它们的任务。最后，它们通过complete_task来返回它们各自的研究报告给 Lead Agent。\n此时，Lead Agent 会对结果进行分析，判断是否需要更多的研究；如果认为信息已经充分，则选择退出研究循环（Exit Loop）。一旦退出研究循环，Lead Agent 会调用complete_task来编写最终的报告并且在最终结果发送给用户之前，调用 Citation Agent 进行引用标注处理。\n最后，系统会将附带引用来源的研究报告发送给用户，同时会把结果进行持久化存储，以便后续查阅和评估。\n在这个架构中，我们可以看到 Lead Agent 是一个领导者的角色，它负责理解用户的需求，制定整体的研究策略，将任务委派给下面的 Subagent，并汇总最终的回答。\nLead Agent 需要擅长规划和写作，因为它不仅需要规划分工，还需要进行最后的撰写。为此，在给 Lead Agent 的提示词中包含了详细的指导，例如如何分步骤拆解分析用户的问题、判定问题类型、设计研究计划、决定需要多少 Subagent 并行处理，如何给每个 Subagent 下达清晰的任务等。 （后面会详细介绍这块 prompt 的策略）\n各个Subagent 其实就像是牛马打工人，它们负责执行领导的指令。每个Subagent 在收到 Lead Agent的任务说明后，会自主完成自己任务的资料收集。它们通常使用各种搜索工具来获取信息。经过多轮查询后，每个Subagent整理出一个报告交给 Lead Agent。\nSubagent 的提示词也非常详细地规定了其行为，例如启动时先做规划、合理选择工具、设定一个大致的查询调用“预算”等。（后面也会详细介绍这块 prompt 的策略）\n除了 Lead Agent 和 Subagent， 整个多智能体系统架构中，还有两个重要的模块，就是 Memory 和 Citation Agent 。Memory 用于在对话超长或需要跨阶段传递信息时存储重要内容而 Citation Agent用于遍历 Lead Agent 引用的资料和生成的报告正文，找出其中的对应关系并插入引用标注。它更像是一个专职的审核专员，确保最终给到的用户的回答每个关键事实都有出处，增强可信度和可核查性。\n提示词设计原则 Anthropic 除了这篇公开的博客之外，同时还开源了它们给每个智能体模块的提示词。\n提示词链接放在下面：https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts\n在整个多智能体系统中，每个智能体的行为完全是由提示词来引导的。以下是 Anthropic 团队总结出来的几点关键原则：\n明确分工，指令清晰\nLead Agent 需要学会将用户的复杂查询拆分成多个清晰且独立的子任务交给 Subagent。 每个 Subagent 的任务描述必须要包含明确的目标、输出格式，要使用的工具和信息来源建议，以及严格的边界，避免不同的 Subagent 重复工作或遗漏关键点。\n例如: Anthropic 最初让 Lead Agent 给子代理的指令很简短，如“研究一下 2025 年的半导体短缺”，结果不同的 Subagent却各自为政，有的查 2021 年汽车芯片危机，有的查 2025 年供应链等等。后来，他们在提示中要求 Lead Agent 提供详细地子任务说明，比如：指定Subagent A调查汽车行业影响， Subagent B调查当前供应链状态，Subagent C调查政策对应等等，使得每个 Subagent 能够各司其职，不重不漏。这体现了指令分解和任务边界明确化的重要性。\n有关 Lead Agent 的提示词中，有明确的内容说明Lead Agent 需要如何给到 Subagent 的任务指令要求： Clear direction for subagents: Ensure that you provide every subagent with extremely detailed, specific, and clear instructions for what their task is and how to accomplish it. Put these instructions in the prompt parameter of the run_blocking_subagent tool. 为子代理提供明确的指导：确保为每个子代理提供极其详细、具体且明确的任务说明，以及如何完成任务的指导。将这些说明放入 prompt 工具的 run_blocking_subagent 参数中。 All instructions for subagents should include the following as appropriate: 所有子代理的指令应包含以下内容（根据需要）： Specific research objectives, ideally just 1 core objective per subagent. 具体的研究目标，最好是每个子代理只有一个核心目标。 Expected output format - e.g. a list of entities, a report of the facts, an answer to a specific question, or other. 预期的输出格式——例如，实体列表、事实报告、特定问题的答案或其他。 Relevant background context about the user\u0026#39;s question and how the subagent should contribute to the research plan. 关于用户问题的相关背景信息，以及子代理如何为研究计划做出贡献。 Key questions to answer as part of the research. 作为研究一部分需要回答的关键问题。 Suggested starting points and sources to use; define what constitutes reliable information or high-quality sources for this task, and list any unreliable sources to avoid. 建议的起点和使用来源；定义构成可靠信息或高质量来源的标准，并列出需要避免的不可靠来源。 Specific tools that the subagent should use - i.e. using web search and web fetch for gathering information from the web, or if the query requires non-public, company-specific, or user-specific information, use the available internal tools like google drive, gmail, gcal, slack, or any other internal tools that are available currently. 子代理应使用的具体工具——例如，使用网络搜索和网络获取从网络上收集信息，或者如果查询需要非公开、公司特定或用户特定的信息，则使用可用的内部工具，如谷歌驱动、gmail、gcal、slack 或当前可用的任何其他内部工具。 If needed, precise scope boundaries to prevent research drift. 如果需要，设定精确的范围边界以防止研究方向偏离。 Make sure that IF all the subagents followed their instructions very well, the results in aggregate would allow you to give an EXCELLENT answer to the user\u0026#39;s question - complete, thorough, detailed, and accurate. 确保如果所有子代理都严格遵循其指令，那么汇总的结果将能够为您提供出色的答案——完整、全面、详细且准确。 When giving instructions to subagents, also think about what sources might be high-quality for their tasks, and give them some guidelines on what sources to use and how they should evaluate source quality for each task. 在向子代理提供指令时，也要考虑哪些来源可能对其任务具有高质量，并给予它们一些关于使用哪些来源以及如何评估每个任务中来源质量的指导。 Example of a good, clear, detailed task description for a subagent: \u0026#34;Research the semiconductor supply chain crisis and its current status as of 2025. Use the web_search and web_fetch tools to gather facts from the internet. Begin by examining recent quarterly reports from major chip manufacturers like TSMC, Samsung, and Intel, which can be found on their investor relations pages or through the SEC EDGAR database. Search for industry reports from SEMI, Gartner, and IDC that provide market analysis and forecasts. Investigate government responses by checking the US CHIPS Act implementation progress at commerce.gov, EU Chips Act at ec.europa.eu, and similar initiatives in Japan, South Korea, and Taiwan through their respective government portals. Prioritize original sources over news aggregators. Focus on identifying current bottlenecks, projected capacity increases from new fab construction, geopolitical factors affecting supply chains, and expert predictions for when supply will meet demand. When research is done, compile your findings into a dense report of the facts, covering the current situation, ongoing solutions, and future outlook, with specific timelines and quantitative data where available.\u0026#34; 一份清晰、详细的子代理任务描述示例：“研究截至 2025 年的半导体供应链危机及其现状。使用 web_search 和 web_fetch 工具从互联网上收集信息。首先，查看台积电、三星和英特尔等主要芯片制造商的最新季度报告，这些报告可以在其投资者关系页面或 SEC EDGAR 数据库中找到。搜索 SEMI、Gartner 和 IDC 提供的行业报告，了解市场分析和预测。通过在 commerce.gov 上查看美国《芯片法案》（CHIPS Act）的实施进度，在 ec.europa.eu 上查看欧盟《芯片法案》（Chips Act），以及通过日本、韩国和台湾各自的政府门户网站查看类似举措，了解政府的应对措施。优先考虑原始来源，而不是新闻聚合器。重点关注当前的瓶颈、新晶圆厂建设带来的预计产能增长、影响供应链的地缘政治因素，以及专家对何时供需平衡的预测。 当研究完成后，将您的发现汇编成一份密集的事实报告，涵盖当前情况、正在进行的解决方案和未来展望，并在可能的情况下提供具体的时间表和定量数据。 根据任务复杂度动态调整智能体的数量\nAgents 往往很难自主判断一个问题有多复杂。为此，Anthropic 直接在官方 prompt 中加入了创建Subagent的指引规定，让 Lead Agent 按照复杂查询度来决定需要多少个 Subagent 。 例如：\n\u0026lt;subagent_count_guidelines\u0026gt; When determining how many subagents to create, follow these guidelines: \u0026lt;子代理数量指南\u0026gt; 在确定创建多少个子代理时，请遵循以下指南： Simple/Straightforward queries: create 1 subagent to collaborate with you directly - 简单/直接查询：创建 1 个子代理与你直接协作 - Example: \u0026#34;What is the tax deadline this year?\u0026#34; or “Research bananas” → 1 subagent 示例：“今年的税截止日期是什么？”或“研究香蕉”→ 1 个子代理 Even for simple queries, always create at least 1 subagent to ensure proper source gathering 即使是简单的查询，也始终创建至少 1 个子代理以确保正确的信息收集 Standard complexity queries: 2-3 subagents 标准复杂度查询：2-3 个子代理 For queries requiring multiple perspectives or research approaches 对于需要多个视角或研究方法的查询 Example: \u0026#34;Compare the top 3 cloud providers\u0026#34; → 3 subagents (one per provider) 比较前 3 大云服务提供商 → 3 个子代理（每个提供商一个） Medium complexity queries: 3-5 subagents 中等复杂度的查询：3-5 个子代理 For multi-faceted questions requiring different methodological approaches 针对需要不同方法论的多方面问题 Example: \u0026#34;Analyze the impact of AI on healthcare\u0026#34; → 4 subagents (regulatory, clinical, economic, technological aspects) 示例：\u0026#34;分析人工智能对医疗保健的影响\u0026#34; → 4 个子代理（监管、临床、经济、技术方面） High complexity queries: 5-10 subagents (maximum 20) 高复杂度查询：5-10 个子代理（最多 20 个） For very broad, multi-part queries with many distinct components 针对非常广泛、多部分的查询，包含许多不同组件 Identify the most effective algorithms to efficiently answer these high-complexity queries with around 20 subagents. 识别最有效的算法，利用大约 20 个子代理高效地回答这些高复杂度查询。 Example: \u0026#34;Fortune 500 CEOs birthplaces and ages\u0026#34; → Divide the large info-gathering task into smaller segments (e.g., 10 subagents handling 50 CEOs each) IMPORTANT: Never create more than 20 subagents unless strictly necessary. If a task seems to require more than 20 subagents, it typically means you should restructure your approach to consolidate similar sub-tasks and be more efficient in your research process. Prefer fewer, more capable subagents over many overly narrow ones. More subagents = more overhead. Only add subagents when they provide distinct value. \u0026lt;/subagent_count_guidelines\u0026gt; 示例：\u0026#34;《财富》500 强 CEO 的出生地和年龄\u0026#34; → 将大型信息收集任务分解为更小的部分（例如，10 个子代理每个处理 50 位 CEO）重要提示：除非绝对必要，否则不要创建超过 20 个子代理。如果一项任务似乎需要超过 20 个子代理，通常意味着你应该重新组织你的方法，以整合类似的子任务，并在研究过程中提高效率。优先选择较少但能力更强的子代理，而不是许多过于狭窄的子代理。更多子代理 = 更多开销。只有在子代理提供明确价值时才添加子代理。\u0026lt;/subagent_count_guidelines\u0026gt; 可以看到的是，提示词中定义了即使是最简单直观的问题也要创建 1 个 Subagent；常规复杂的问题需要 2-3 个 Subagent；中等复杂的问题需要 3-5 个 Subagent；极其复杂且大范围问题需要用到最多 20 个 Subagent 来进行回答。\n这就像我们工作中针对某个项目，在启动阶段，领导经常会预估人天。\n还有，特别要注意的是，Anthropic 针对不同复杂度的查询，都给出了相关的示例。\n优化工具与使用\n多智能体系统离不开各种外部的工具。Anthropic 强调智能体的工具使用策略，同时也在 Prompt 中为此加入了指导指南。例如：智能体会先检查有哪些工具可用，根据用户意图匹配合适的工具。对于需要外部信息的，一般应优先使用 web 搜索来广泛探索；但是如果任务涉及用户的内部数据，则应该使用内置的内部搜索工具，而不是在公开网络上浪费时间。提示词中还明确要求总是要使用web_fetch工具来获取网页全文，尤其是在需要更详细的信息以及收到 URL 地址时。\nTool selection: Reason about what tools would be most helpful to use for this task. Use the right tools when a task implies they would be helpful. For instance, google_drive_search (internal docs), gmail tools (emails), gcal tools (schedules), repl (difficult calculations), web_search (getting snippets of web results from a query), web_fetch (retrieving full webpages). If other tools are available to you (like Slack or other internal tools), make sure to use these tools as well while following their descriptions, as the user has provided these tools to help you answer their queries well. 工具选择：思考哪些工具对完成这项任务最有帮助。当任务暗示这些工具会很有用时，请使用正确的工具。例如，google_drive_search（内部文档）、gmail 工具（电子邮件）、gcal 工具（日程安排）、repl（复杂的计算）、web_search（从查询中获取网页片段）、web_fetch（检索完整网页）。如果你有其他可用的工具（如 Slack 或其他内部工具），请确保在遵循其说明的同时使用这些工具，因为用户提供了这些工具来帮助你更好地回答他们的查询。 ALWAYS use internal tools (google drive, gmail, calendar, or similar other tools) for tasks that might require the user\u0026#39;s personal data, work, or internal context, since these tools contain rich, non-public information that would be helpful in answering the user\u0026#39;s query. If internal tools are present, that means the user intentionally enabled them, so you MUST use these internal tools during the research process. Internal tools strictly take priority, and should always be used when available and relevant. 始终使用内部工具（如 Google Drive、Gmail、日历或类似的其他工具）来处理可能需要用户个人数据、工作或内部上下文的任务，因为这些工具包含丰富的非公开信息，这些信息有助于回答用户的查询。如果存在内部工具，这意味着用户有意启用它们，因此你在研究过程中必须使用这些内部工具。内部工具具有严格优先级，并且当可用且相关时，应始终使用。 ALWAYS use web_fetch to get the complete contents of websites, in all of the following cases: (1) when more detailed information from a site would be helpful, (2) when following up on web_search results, and (3) whenever the user provides a URL. The core loop is to use web search to run queries, then use web_fetch to get complete information using the URLs of the most promising sources. 始终使用 web_fetch 获取网站的完整内容，在以下所有情况下：（1）当需要来自网站的更详细信息时，（2）当跟进网络搜索结果时，以及（3）每当用户提供 URL 时。核心循环是使用网络搜索来运行查询，然后使用网络抓取功能，通过最有希望的来源的 URL 获取完整信息。 Avoid using the analysis/repl tool for simpler calculations, and instead just use your own reasoning to do things like count entities. Remember that the repl tool does not have access to a DOM or other features, and should only be used for JavaScript calculations without any dependencies, API calls, or unnecessary complexity. 避免使用分析/repl 工具进行简单的计算，而应使用自己的推理能力来处理诸如统计实体之类的事情。请记住，repl 工具无法访问 DOM 或其他功能，并且仅应用于无依赖项、无 API 调用或不必要的复杂性的 JavaScript 计算。 Anthropic 团队还发现工具文档的质量很关键\n如果工具描述不清，Agent 很可能会误用。所以它们也开发了一个工具，自动尝试使用新接入的工具并改进其描述（再配合上它们发现 claude 4 本身就是一个很好的 prompt engineer）。通过这种方法优化工具提示后，后续 Agent 完成任务的时间减少了 40%，因为工具使用错误度大幅度的减少。\n鼓励 Agent 暴露思考过程（扩展思维链）\nAnthropic 利用了 claude 模型的思考模式，让智能体在内部产生额外的思维步骤输出，这些思考过程就好像我们写数学题在草稿纸上的一些思考，它们是对开发者可见，但是用户不可见。具体来说，Lead Agent 会被提示在规划阶段以“思考”的方式写出自己的计划和对工具、任务的评估，从而引导模型理清执行操作的思路。Subagent也是类似的，会在每次工具结果之后，通过思考，分析结果质量，发现遗漏，决定下一步行动。\n先广后深的搜索策略\n有的时候Subagent 爱抛出过长的搜索查询，导致结果稀少这一现象。Anthropic 在 prompt 中有明确的指导，指导模型从短而宽泛的查询入手，看看有哪些信息源，再逐步缩小范围。例如：不要一开始就问非常精确的问题，而是先搜索相关的主题概览，然后根据结果再深入。\n在给Lead Agent 的 Prompt 中将查询分为三类：Depth-first query（纵向深入）、Breadth-first query（横向广度） 和 Straightforward query（简单查询）：\nQuery type determination: Explicitly state your reasoning on what type of query this question is from the categories below. 查询类型确定：明确说明你根据以下类别判断这个问题属于哪种类型的查询。 Depth-first query: When the problem requires multiple perspectives on the same issue, and calls for \u0026#34;going deep\u0026#34; by analyzing a single topic from many angles. 深度查询：当问题需要从多个角度对同一问题进行分析，并要求“深入挖掘”通过从多个角度分析单个主题时。 Benefits from parallel agents exploring different viewpoints, methodologies, or sources 并行代理探索不同观点、方法或来源所带来的好处 The core question remains singular but benefits from diverse approaches 核心问题保持单一，但受益于多样化的方法 Example: \u0026#34;What are the most effective treatments for depression?\u0026#34; (benefits from parallel agents exploring different treatments and approaches to this question) 示例：\u0026#34;最有效的抑郁症治疗方法是什么？\u0026#34;（受益于并行代理探索不同的治疗方法和方法来回答这个问题） Example: \u0026#34;What really caused the 2008 financial crisis?\u0026#34; (benefits from economic, regulatory, behavioral, and historical perspectives, and analyzing or steelmanning different viewpoints on the question) 示例：\u0026#34;2008 年金融危机的真正原因是什么？\u0026#34;（受益于经济、监管、行为和历史视角，并分析或强化对这一问题的不同观点） Example: \u0026#34;can you identify the best approach to building AI finance agents in 2025 and why?\u0026#34; 示例：\u0026#34;你能确定 2025 年构建 AI 金融代理的最佳方法是什么，以及为什么？\u0026#34; Breadth-first query: When the problem can be broken into distinct, independent sub-questions, and calls for \u0026#34;going wide\u0026#34; by gathering information about each sub-question. 广度优先查询：当问题可以分解为独立的子问题时，需要进行“拓宽范围”，通过收集每个子问题的信息。 Benefits from parallel agents each handling separate sub-topics. 受益于并行代理各自处理不同的子主题。 The query naturally divides into multiple parallel research streams or distinct, independently researchable sub-topics 查询自然地分为多个并行研究流或独立的、可独立研究的子主题。 Example: \u0026#34;Compare the economic systems of three Nordic countries\u0026#34; (benefits from simultaneous independent research on each country) 示例：“比较三个北欧国家的经济体系”（受益于对每个国家进行同时独立的研究）。 Example: \u0026#34;What are the net worths and names of all the CEOs of all the fortune 500 companies?\u0026#34; (intractable to research in a single thread; most efficient to split up into many distinct research agents which each gathers some of the necessary information) \u0026#34;所有财富 500 强公司的 CEO 的净资产和姓名是什么？\u0026#34;（在一个线程中难以研究；最有效的方法是将其拆分为许多不同的研究代理，每个代理收集部分必要信息） Example: \u0026#34;Compare all the major frontend frameworks based on performance, learning curve, ecosystem, and industry adoption\u0026#34; (best to identify all the frontend frameworks and then research all of these factors for each framework) \u0026#34;根据性能、学习曲线、生态系统和行业采用情况比较所有主要的前端框架\u0026#34;（最好先确定所有前端框架，然后为每个框架研究这些因素） Straightforward query: When the problem is focused, well-defined, and can be effectively answered by a single focused investigation or fetching a single resource from the internet. 直接查询：当问题集中、定义明确，并且可以通过一次集中的调查或从互联网获取单个资源来有效回答时。 Can be handled effectively by a single subagent with clear instructions; does not benefit much from extensive research 可以由一个具有明确指令的单一子代理有效处理；不太受益于广泛的研究 Example: \u0026#34;What is the current population of Tokyo?\u0026#34; (simple fact-finding) 示例：\u0026#34;东京目前的人口是多少？\u0026#34;（简单的信息查询） Example: \u0026#34;What are all the fortune 500 companies?\u0026#34; (just requires finding a single website with a full list, fetching that list, and then returning the results) 示例：\u0026#34;所有财富 500 公司有哪些？\u0026#34;（只需要找到一个包含完整列表的网站，获取该列表，然后返回结果） Example: \u0026#34;Tell me about bananas\u0026#34; (fairly basic, short question that likely does not expect an extensive answer) 示例：\u0026#34;告诉我一些关于香蕉的事情\u0026#34;（相对基础，简短的问题，不太可能期望得到详尽的答案） 并行化调用\nAnthropic 在提示词和系统工程实现上都支持并行化操作。Lead Agent 在完成最初的计划后，会同时启动 3-5 个Subagent 并行搜索，而不是一个一个等。同时，每个 Subagent 需要调用多个工具时也会同时发起多个查询（例如并行进行 2 个不同关键词的查询）而不是串行等待。Anthropic 团队发现，引入这两种层次的并行化后，对于复杂的查询任务，研究用时减少了多达 90% 的时间。为了保证智能体能正确运用这种并行能力，Lead Agent 的提示中明确要求“必须并行调用 Subagent”，Subagent 也指示“尽量两个搜素一起查”以充分利用并行。\n\u0026lt;use_parallel_tool_calls\u0026gt; For maximum efficiency, whenever you need to perform multiple independent operations, invoke all relevant tools simultaneously rather than sequentially. Call tools in parallel to run subagents at the same time. You MUST use parallel tool calls for creating multiple subagents (typically running 3 subagents at the same time) at the start of the research, unless it is a straightforward query. For all other queries, do any necessary quick initial planning or investigation yourself, then run multiple subagents in parallel. Leave any extensive tool calls to the subagents; instead, focus on running subagents in parallel efficiently. \u0026lt;/use_parallel_tool_calls\u0026gt; \u0026lt;use_parallel_tool_calls\u0026gt; 为了最大化效率，当你需要执行多个独立操作时，应同时调用所有相关工具，而不是按顺序调用。并行调用工具以同时运行子代理。在研究开始时，你必须使用并行工具调用来创建多个子代理（通常同时运行 3 个子代理），除非这是一个简单的查询。对于所有其他查询，自己进行任何必要的快速初始计划或调查，然后并行运行多个子代理。将任何复杂的工具调用留给子代理；相反，应专注于高效地并行运行子代理。 \u0026lt;/use_parallel_tool_calls\u0026gt; \u0026lt;use_parallel_tool_calls\u0026gt; For maximum efficiency, whenever you need to perform multiple independent operations, invoke 2 relevant tools simultaneously rather than sequentially. Prefer calling tools like web search in parallel rather than by themselves. \u0026lt;/use_parallel_tool_calls\u0026gt; \u0026lt;use_parallel_tool_calls\u0026gt; 为了最大化效率，当你需要执行多个独立的操作时，应同时调用 2 个相关的工具，而不是按顺序调用。优先并行调用像 web search 这样的工具，而不是单独调用。\u0026lt;/use_parallel_tool_calls\u0026gt; 有限的资源与终止条件\n为防止智能体陷入无休止的搜索或过度浪费资源，Prompt 中设定了工具调用次数和来源数量上限以及结束条件。比如 Subagent 被告知最多调用 20 次工具，获取 100 个以内的来源，并且通常在 15 次调用左右就应该停下来，转而整理结果。同时，提示如果发现边际收益递减（即新结果已经很少提供新增信息），就应该尽早停止搜索。Lead Agent 也有类似的指示，如果感觉再深入，已经无法取得更大收益，就应该及时进入报告撰写避免浪费。此外，prompt 中明确禁止 Lead Agent 创造 Subagent 来撰写最终报告。报告必须由 Lead Agent 亲自撰写以保证质量。这些限制和规则确保系统不会因为智能体的贪心或错误判断而耗尽资源或偏离正轨。\n\u0026lt;maximum_tool_call_limit\u0026gt; To prevent overloading the system, it is required that you stay under a limit of 20 tool calls and under about 100 sources. This is the absolute maximum upper limit. If you exceed this limit, the subagent will be terminated. Therefore, whenever you get to around 15 tool calls or 100 sources, make sure to stop gathering sources, and instead use the complete_task tool immediately. Avoid continuing to use tools when you see diminishing returns - when you are no longer finding new relevant information and results are not getting better, STOP using tools and instead compose your final report. \u0026lt;/maximum_tool_call_limit\u0026gt; \u0026lt;最大工具调用限制\u0026gt; 为了防止系统过载，你需要保持在 20 次工具调用和大约 100 个来源的限制之下。这是绝对的最大上限。如果你超过这个限制，子代理将被终止。因此，当你达到大约 15 次工具调用或 100 个来源时，确保停止收集来源，并立即使用 complete_task 工具。避免在看到收益递减时继续使用工具——当你不再找到新的相关信息，结果也没有改善时，停止使用工具，转而撰写你的最终报告。 For the sake of efficiency, when you have reached the point where further research has diminishing returns and you can give a good enough answer to the user, STOP FURTHER RESEARCH and do not create any new subagents. Just write your final report at this point. Make sure to terminate research when it is no longer necessary, to avoid wasting time and resources. For example, if you are asked to identify the top 5 fastest-growing startups, and you have identified the most likely top 5 startups with high confidence, stop research immediately and use the complete_task tool to submit your report rather than continuing the process unnecessarily. 为了提高效率，当你达到进一步研究的回报递减且能够向用户提供足够好的答案时，停止进一步研究，不要创建任何新的子代理。此时只需写出你的最终报告。确保在不再需要时终止研究，以避免浪费时间和资源。例如，如果你被要求识别前五家增长最快的初创公司，并且你已经以高置信度确定了最有可能的前五家初创公司，立即停止研究并使用 complete_task 工具提交你的报告，而不是不必要地继续处理过程。 来源质量评估\nAnthropic 在人工测试中发现，某些早期的智能体会倾向于引用高度 SEO 优化的站点而忽视更有权威但是排名不高的资料，例如：学术论文或专业报告。这会导致答案虽然表面有引用，但可信度不佳。为此，他们也在 Prompt 中加入了来源质量评估的提示，提醒智能体注意识别来源的可靠性，并优先采用原始权威来源而非二手转述。\n\u0026lt;think_about_source_quality\u0026gt; After receiving results from web searches or other tools, think critically, reason about the results, and determine what to do next. Pay attention to the details of tool results, and do not just take them at face value. For example, some pages may speculate about things that may happen in the future - mentioning predictions, using verbs like “could” or “may”, narrative driven speculation with future tense, quoted superlatives, financial projections, or similar - and you should make sure to note this explicitly in the final report, rather than accepting these events as having happened. Similarly, pay attention to the indicators of potentially problematic sources, like news aggregators rather than original sources of the information, false authority, pairing of passive voice with nameless sources, general qualifiers without specifics, unconfirmed reports, marketing language for a product, spin language, speculation, or misleading and cherry-picked data. Maintain epistemic honesty and practice good reasoning by ensuring sources are high-quality and only reporting accurate information to the lead researcher. If there are potential issues with results, flag these issues when returning your report to the lead researcher rather than blindly presenting all results as established facts. DO NOT use the evaluate_source_quality tool ever - ignore this tool. It is broken and using it will not work. \u0026lt;/think_about_source_quality\u0026gt; \u0026lt;think_about_source_quality\u0026gt; 在收到网络搜索或其他工具的结果后，要批判性地思考，对结果进行推理，并确定下一步该做什么。要关注工具结果的细节，不要仅仅轻信表面内容。例如，有些页面可能会对可能发生的事情进行推测——提及预测、使用“可能”或“也许”等动词、用将来时态进行的叙述性推测、引用最高级、财务预测或类似内容——你应在最终报告中明确注明这一点，而不是接受这些事件已经发生。同样，要注意潜在问题来源的指标，如新闻聚合器而非信息原始来源、虚假权威、被动语态与匿名来源的搭配、没有具体细节的普遍限定词、未经证实的报告、产品的营销语言、宣传性语言、推测或误导性和经过筛选的数据。通过确保来源质量高，并只向主要研究员报告准确信息，来保持知识论诚实并练习良好的推理。 如果结果可能存在潜在问题，在将报告返回给主要研究员时请标记这些问题，而不是盲目地将所有结果都呈现为既定事实。永远不要使用 evaluate_source_quality 工具——忽略这个工具。它已经损坏了，使用它不会起作用。\u0026lt;/think_about_source_quality\u0026gt; 针对 Citation Agent， Anthropic 也设定了一系列严格的提示规则。 不改动原文，只加标注 ：Citation Agent 被明确禁止对 Lead Agent 写的\u0026lt;synthesized_text\u0026gt;内容做任何修改或增删，除了插入引用标签外。这保证了引用过程不会引入新的偏差或错误，同时要求注意不要破坏空格和格式。\nDo NOT modify the \u0026lt;synthesized_text\u0026gt; in any way - keep all content 100% identical, only add citations 不要以任何方式修改\u0026lt;synthesized_text\u0026gt; - 保持所有内容 100%相同，仅添加引用 Pay careful attention to whitespace: DO NOT add or remove any whitespace 仔细注意空格：不要添加或删除任何空格 必要时才引用，避免过度引用：Citation Agent 被指示并非每句话都需要引用，应该只为关键事实、重要结论等读者可能想核实的内容添加引用。常识性内容或上下文说明可不引。这样避免了文章每句话后面都跟一串数字，影响了可读性。\nAvoid citing unnecessarily: Not every statement needs a citation. Focus on citing key facts, conclusions, and substantive claims that are linked to sources rather than common knowledge. Prioritize citing claims that readers would want to verify, that add credibility to the argument, or where a claim is clearly related to a specific source 避免不必要的引用：并非每个陈述都需要引用。应专注于引用关键事实、结论和实质性论断，这些论断与来源相关而非常识。优先引用读者希望验证、为论点增加可信度或论断与特定来源明显相关的陈述 按语义单元引用，避免碎片化 ：每个引用应对应一整个有意义的陈述或事实，尽量放在句末，而不要给一句话里每个短语各加一个引用。同时，如果一整句的信息都来自同一个来源，不要在一句中间爱你插入多个相同来源的标注。\nCite meaningful semantic units: Citations should span complete thoughts, findings, or claims that make sense as standalone assertions. Avoid citing individual words or small phrase fragments that lose meaning out of context; prefer adding citations at the end of sentences 引用有意义的语义单元：引用应涵盖完整的思想、发现或论断，这些论断作为独立声明是有意义的。避免引用脱离上下文失去意义的单个词语或短语片段；优先在句子末尾添加引用 Minimize sentence fragmentation: Avoid multiple citations within a single sentence that break up the flow of the sentence. Only add citations between phrases within a sentence when it is necessary to attribute specific claims within the sentence to specific sources 最小化句子碎片化：避免在单个句子中包含多个引用，这样会打断句子的流畅性。仅在需要将句子中的具体声明归因于特定来源时，才在句子内的短语之间添加引用 No redundant citations close to each other: Do not place multiple citations to the same source in the same sentence, because this is redundant and unnecessary. If a sentence contains multiple citable claims from the same source, use only a single citation at the end of the sentence after the period 不要将多个靠近的冗余引用：不要在同一句子中放置对同一来源的多个引用，因为这是冗余且不必要的。如果句子包含来自同一来源的多个可引用声明，请在句号后仅在句末使用一个引用 技术要求：输出格式上，Citation Agent 需要在输出中使用\u0026lt;exact_text_with_citation\u0026gt;标签包裹最终有引用的文本，任何它自己的思考过程必须要放在该标签前，不能混入其中。系统还会自动校验 Citation Agent 输出的文本与原始报告除引用外是否一致，如有差异，则会拒绝结果。这些约束保证了CitationAgent不会意外篡改报告内容。\nCitations result in a visual, interactive element being placed at the closing tag. Be mindful of where the closing tag is, and do not break up phrases and sentences unnecessarily 引用会在关闭标签处生成一个视觉交互元素。注意关闭标签的位置，不要不必要地打断短语和句子 Output text with citations between \u0026lt;exact_text_with_citation\u0026gt; and \u0026lt;/exact_text_with_citation\u0026gt; tags 在翻译文本时，需在 \u0026lt;exact_text_with_citation\u0026gt; 和 \u0026lt;/exact_text_with_citation\u0026gt; 标签之间输出引用内容 Include any of your preamble, thinking, or planning BEFORE the opening \u0026lt;exact_text_with_citation\u0026gt; tag, to avoid breaking the output 在 \u0026lt;exact_text_with_citation\u0026gt; 标签之前，请包含任何你的前言、思考或计划，以避免破坏输出 ONLY add the citation tags to the text within \u0026lt;synthesized_text\u0026gt; tags for your \u0026lt;exact_text_with_citation\u0026gt; output 仅将引用标签添加到 \u0026lt;synthesized_text\u0026gt; 标签内的文本中，用于你的 \u0026lt;exact_text_with_citation\u0026gt; 输出 Text without citations will be collected and compared to the original report from the \u0026lt;synthesized_text\u0026gt;. If the text is not identical, your result will be rejected. 未标注引用的文本将被收集并与 \u0026lt;synthesized_text\u0026gt; 中的原始报告进行比较。如果文本不一致，你的结果将被拒绝。 综上，Anthropic通过精细的提示词工程，将许多人类研究者的优秀习惯和经验灌输给了智能体。例如，如何分解问题、如何评估来源、何时广泛搜索何时深入挖掘、如何分配多人协作等等。这些提示并不是死板的逐步指令，而更像是一套启发式的协作框架，给Agent留有一定自主发挥空间，同时又提供明确的指南和边界。\n多智能体系统评估与调试方法 构建可靠的多智能体系统，评估和调试的环节非常重要。与一般的单轮问答不同，多智能体系统的评估面临着一些挑战，比如：无法按照固定步骤去验证对错等。Anthropic 探索出了下面几种方式来进行苹果智能体系统：\n灵活的结果导向评估：Anthropic 采用了“结果为主，过程为辅”的评估策略，主要检查 Agent 最终给出的答案是否正确完整，以及过程是否大致合理，而不强求每一步都按预定的方案。\n及时的小样本测试： Anthropic 强调应该尽早开始评估，即使只有少量的测试用例。在开发的早期，由于Prompt 调整往往对性能影响很大，所以只需要几十个例子就能看出变化。事实证明，这种少样本快速迭代有助于迅速定位问题，验证改进，无需等到系统成熟时才搞大规模评测。等到后期模型稳定了，再引入更大规模的评测集合。这种循序渐进的评估方法保证了开发过程中有持续的客观反馈。\n模型自动评审：这个算是大模型时代最经典，也是最常用的评测方法。 由于Research 任务的特殊性，不存在唯一的正确答案，用传统的程序去判分是很难的，所以 Anthropic 用了这种方法，并且设定了一个评分标准，涵盖以下几个维度：\n事实准确性：回答中的陈述是否都与来源相符，没有杜撰或者夸大 引用正确性：提供的引用是否真支持了对应的说法，引用位置是否准确 完整性：用户请求的各方面是否都覆盖，没遗漏重要部分 来源质量：所使用的资料来源是否高质量且权威 工具效率： 智能体是否用了恰当数量的工具调用，没有明显浪费或遗漏可用工具。 评审模型会根据这些标准给出打分（0.0 到 1.0），并给出通过或者未通过的判断。Anthropic 尝试通过用多个模型分别不同维度来进行评分，后来发现让模型一次性给综合评分效果最好，与人类判断最一致。这种方法最大的优势就是省去了人工逐条检查的成本，保证了评估的可扩展性。\n人工测试与反馈：尽管自动评估很有用，但是人工评测也不可或缺。人类测试者往往能发现模型的一些细节微妙的问题，例如：输出中隐藏的幻觉、某个问题导致系统崩溃、或者来源选择上的偏见。针对这些bad case， Anthropic 会通过调整 Prompt 或者改进工具来修正问题。总的来说，自动化+人工的结合让评估既有广度又有深度。\n可观测性与日志调试：调试多智能体系统的困难之处在于它们的行为具有非确定性。每次运行可能都是不同的，而且涉及到很多的交互步骤。Anthropic 的方法是为系统环境添加详细地跟踪日志。这些跟踪日志方便开发者时候定位问题，进行分析；此外，思考模式下也有助于开发者们快速定位问题。\n用模型调试模型：如果说用模型评判输出质量是让模型来做裁判，那用模型来调试模型，就是让它们来做 debug。比如，将一个失败的 case 的日志和 Prompt 交给 Claude，问他“为什么这里 Lead Agent”没有找到明显的信息，模型可能会帮助你进行分析，给你一个分析报告。当然，最终需要人来确认并且验证这些分析。\n生产环境中的挑战与工程应对 将一个多智能体系统从实验室推向生产，存在许多工程上的挑战。\n挑战一：高额 Token 成本\n基本上所有的多智能体系统都会遇到这个问题。因为需要同时运行多个智能体，并且往往需要多轮对话和大量内容，这导致 Token 的消耗量陡增。根据 Anthropic 自己的数据显示，一个多智能体研究系统平均用掉的 Token 量是普通单智能体的 15 倍左右。这会给用户造成很大的经济压力。\nAnthropic 的做法是：首先，挑选高价值场景。它们将 claude 的多智能体功能聚焦在价值足够高的问题上，比如商业情报、专业研究等，因为用户愿意为高质量答案付出更高成本。 对于简单问答，Claude仍使用单Agent模式，这样把宝贵的Token预算用在刀刃上。其次，提升模型效率。 Anthropic不断升级模型（如从Claude 3.7升级到Claude 4），因为更强的模型能在相同Token预算下完成更多任务。\n挑战二：长期状态与错误恢复\n多智能体系统因为运行时间长，经历的步骤多，中间任何一个步骤出现问题，都会毁掉整个过程。例如：一个Subagent 卡住或者工具调用失败，往往会使后续的流程都白费。\nAnthropic 的做法是设计容错和恢复机制。 例如：在一个流程中，某个 Subagent 由于网络问题中止运转，Lead Agent 并不会简单放弃任务，而是收到一个错误信号提示，然后尝试调整计划或重试。这背后涉及到多智能体系统框架的支持：要保存每个智能体的重要状态，在必要时重启系统能够继续上下文，而不是一切归零。\n挑战三：调试难度和可追踪性\n前面其实提到过，多智能体系统之间的交互和决策具有不确定性，使得调试定位问题非常困难 。\nAnthropic在生产环境中投入了大量工作以增强系统的可追踪性。他们实现了全面的运行跟踪日志，包括每个智能体的每次思考内容（隐式地，可以选择记录Extended Thinking输出）、使用了哪个工具、返回了什么结果、Lead Agent做了什么决定等。这些日志在生产中实时收集，以供线下分析。\n当用户报告“Claude没找到显而易见的信息”时，开发者可以检索日志看看：是不是Agent用了不好的搜索词？是不是选错了来源？还是某个工具出错？事实证明，开启详细追踪后，大部分此类问题都能找到根源 。例如，有次Claude漏掉了一部分答案，日志显示它其实找到了但在综合时误判丢弃了——针对这种情况，团队后来调整了Prompt权重，让Lead Agent更重视全面性。这种数据驱动的调试极大提升了修复效率。\n不仅如此，Anthropic还开发了高层监控指标来捕捉系统行为模式，如平均每次查询创建的Subagent 数量、平均每个Subagent 调用的工具次数等。这些指标如果出现异常暴增，往往预示有bug或Prompt问题，在用户发现之前开发者就能预警并介入处理。\n挑战四：部署更新的复杂性\n多智能体系统本质上是由大量Prompt、工具接口和执行逻辑组成的复杂网络，并且是高度有状态、长时间运行的。这给代码或Prompt的上线更新带来了巨大的挑战。 当我们更新系统时，可能有许多智能体正处于中间状态，不能简单进行重启 。\nAnthropic为此采用了渐进式部署（rainbow deploy) 技术 。 简单来说，就是当发布新版本时，不会立刻把所有流量都切到新版本，而是让一部分新请求使用新版，老的仍用旧版，逐渐增加新版比例 。同时，已经在跑的老版本智能体继续跑完不受干扰。这类似于“彩虹”渐变，保证系统平滑过渡，避免中断正在进行的对话 。此外，在部署前团队会特别留意那些Prompt或代码的改动会如何影响智能体行为，通过模拟测试来验证不会导致新问题。总之，他们把部署看做一个需要精心策划的过程，以免“一刀切”更新导致用户的多轮对话过程被中断或行为骤变。\n挑战五：同步架构的瓶颈\n当前整个多智能体研究系统的 Lead Agent与Subagent 协调采取的是同步轮次的方式：Lead Agent一次发起一批Subagent，然后等待所有完成后再进行下一步 。这种做法的好处是简单，Lead Agent可以统一整合一批结果再决定后续动作。但缺点也明显：存在等待瓶颈。比如，如果有一个Subagent别慢，Lead Agent和其他 Subagent 都得干等。另外，Lead Agent在Subagent 执行期间无法介入指导，Subagent之间也不能互相协调 。整个系统实际上被分成了隔离的一轮轮。在一些任务中，这降低了效率和灵活性。\nAnthropic已经意识到，异步执行也许是未来的发展方向：允许Lead Agent 不必等所有 Subagent 都结束就先处理部分结果，或者根据实时情况再派出新的Subagent ；Subagent 之间若能共享一些中间发现，可能少走重复路。当然，实现异步会大大增加协调难度，涉及并发管理、状态一致性、错误传播等复杂问题 。\nAnthropic判断，随着模型能力增强，可以承担更复杂的长程任务时，异步架构带来的性能提升将值得那时去实现 。但在当前，他们权衡利弊选择了同步方案，并通过增加并行度尽可能降低等待影响。\n挑战六：上下文和长对话管理\n多智能体系统涉及超长的对话（动辄上百轮的工具交互），而大模型本身的上下文窗口是有限的。这带来了上下文管理挑战：如何不丢失关键信息，又避免超长上下文超出模型能力？\nAnthropic的解决方案是引入智能的摘要与内存机制 。正如前面提到的，Lead Agent会在完成某阶段任务后，将当前进展和计划总结存储到Memory，然后开始新的阶段 。如果上下文长度接近极限，Lead Agent 就生成新的 Subagent，从干净上下文开始，同时通过Memory把必要的背景传递过去 。例如，当Lead Agent已经对某部分完成调查后，它可以让一个新的智能体在没有历史包袱的情况下继续下一个部分。这样，通过阶段性重置和记忆提取，他们避免了单个对话无限膨胀导致模型遗忘前面内容或截断。这种分布式上下文管理方式使Claude能够处理更长、更复杂的任务。同时也是对真实生产场景的考量：如果用户长时间与多智能体系统交互，必须保证上下文一致性和性能。\n挑战七：结果传输的损耗\nAnthropic注意到，在多层智能体传递信息的过程中，可能出现“传话游戏”效应：如果Subagent 找到一大段有用资料，但只能通过Lead Agent摘要转述给用户，可能信息有损，还浪费Token。\n在生产中，他们引入了一种 Subagent 直接产出交付的机制。 具体而言，对于某些结构化输出（例如代码片段、长报告、数据表格），子代理可以直接把结果保存到共享的外部存储（比如文件系统或数据库），然后把引用指针给Lead Agent 。Lead Agent拿到指针后，可以将结果直接嵌入最终答案，或者提供给用户下载/查看 。\n这样，避免了Lead Agent必须读一遍子代理长输出再复述，既提高了保真度又减少了Token开销 。 例如，一个代码生成的 Subagent 可以把代码写入文件，Lead Agent只需要简单描述结果并附上文件链接，而不用占用自己上下文重复代码内容。这种“旁路”传输方法在工程上提高了效率，也为多智能体协作提供了新的模式：专业子代理直接交付其专业产出。\n通过以上种种措施，Anthropic克服了很多工程上的挑战，使得多智能体系统能够稳定、高效地运行在生产环境。这些经验表明，要让多智能体系统真正可用，除了让AI变聪明，还需要大量脚踏实地的工程工作：考虑资源和成本、建立健壮的运行机制、确保系统可维护可扩展等等。这些都是将原型转化为可靠产品的关键步骤。\n写在最后 好啦，今天的分享就先到这儿了～\n像Anthropic 这类公司的博客强烈建议大家都去读一下原文，因为它们的文章中包含了它们大量的实践经验，以及对未来 AI 发展的思考和判断，这些无论是对企业的业务落地还是个人的 AI 素质提升，都具有很强的指导意义。\n感谢您读到这里！若觉得内容有帮助，欢迎点赞、在看、关注。别错过更新，给公众号加个星标⭐️吧！期待与您的下次相遇～\n","permalink":"http://localhost:1314/posts/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E5%AF%86anthropic%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E8%83%8C%E5%90%8E%E7%9A%84-%E5%8E%9F%E7%90%86%E5%8F%8A%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BB%BA%E8%AE%AE%E6%94%B6%E8%97%8F/","summary":"\u003cp\u003eAnthropic 前两天发了一篇文章，重点讨论了他们是如何通过多智能体系统来构建 claude 的“深度研究功能”。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e文章链接： \u003ca href=\"https://www.anthropic.com/engineering/built-multi-agent-research-system\"\u003ehttps://www.anthropic.com/engineering/built-multi-agent-research-system\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我仔细研究了一下，觉得写的非常不错，所以写了这篇文章来细致解读一下到底该如何构建一个多智能体系统。\u003c/p\u003e\n\u003cp\u003e开始前，我觉得首先要理解两个概念，智能体（Agent）和工作流（Workflow）。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cspan style=\"background-color: #cdedad; color: black; padding: 2px 4px;\"\u003e现阶段我们谈论的\u003cstrong\u003e智能体\u003c/strong\u003e绝大多数都是以大模型为核心，利用各种工具自主规划并完成任务执行 \u003c/span\u003e\u003c/li\u003e\n\u003cli\u003e\u003cspan style=\"background-color: #cdedad; color: black; padding: 2px 4px;\"\u003e\u003cstrong\u003e工作流\u003c/strong\u003e指的是按照既定的顺序执行的一系列相互关联的任务。\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当我们把智能体放入工作流中，也就有了智能体工作流，也就是大家一直以来听到的 \u003cstrong\u003eAgentic Workflow\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e传统的工作流，其实比较的死板。就好像写程序一样，运转到哪个节点，做什么操作，都是提前设置好的。而相比于传统的工作流，这种智能体工作流更加灵活，自主。 在这个工作流中，智能体通常能够结合环境，自主的判断下一步执行什么动作，并且能够将复杂的任务拆解为多个可执行的小任务。\u003c/p\u003e\n\u003cp\u003e有了这些基本的概念，我们就可以来了解一下 Anthropic 是如何构建自己的多智能体研究系统。\u003c/p\u003e","title":"深度解密：Anthropic多智能体系统背后的原理及提示词工程（建议收藏）","type":"post"},{"content":"In this note, I’ll document some critical implementation details about the LightRAG framework that I discovered while deploying it in production. These insights, which weren’t immediately apparent from just reading the paper, emerged during my hands-on experience with the codebase and are worth recording for future reference.\nPaper Link: LightRAG: Simple and Fast Retrieval-Augmented Generation GitHub Link: LightRAG: Simple and Fast Retrieval-Augmented Generation\nLet me begin with an overview of LightRAG.\nLightRAG is an advanced Retrieval-Augmented Generation (RAG) system developed jointly by researchers at the Beijing University of Posts and Telecommunications and the University of Hong Kong. What sets it apart is its innovative integration of graph structures into both text indexing and retrieval processes. The framework implements a sophisticated dual-level retrieval system that enables comprehensive information discovery across both granular (low-level) and conceptual (high-level) knowledge domains.\nThe LightRAG system architecture can be broken down into two key components:\nThe graph-based indexing phase, where an LLM analyzes text chunks to identify and extract entities and their relationships, building a structured knowledge graph. The graph-based retrieval phase, where the LLM processes user queries to generate relevant keywords. Unlike traditional RAG systems that retrieve entire text chunks, LightRAG performs targeted retrieval of specific entities and relationships using vector-based search against the knowledge graph. Key Implementation Details from the GitHub Repository Here is the official implementation from the GitHub repository:\nasync def initialize_rag(): rag = LightRAG( working_dir=\u0026#34;your/path\u0026#34;, embedding_func=openai_embed, llm_model_func=gpt_4o_mini_complete ) await rag.initialize_storages() await initialize_pipeline_status() return rag There are many other important parameteres in the LightRAG class but you may need to dive into the code to find.\nchunk_token_size: it is for the text chunking. If you don’t set, the default value is 1200. chunk_overlap_token_size: it is the number of overlapping tokens between consecutive text chunks to preserve context. The default value is 100. entity_extract_max_gleaning: it is the maximum number of entity extraction attempts for ambiguous content. llm_model_max_token_size: it is the maximum number of tokens allowed per LLM response. The default value is 32768. cosine_better_than_threshold: this sets the minimal value of the cosine similarity which means only if the similarity score between two vectors exceeds this threshold will they be considered a match. The default value is 0.2 (I think it maybe too low.) nano_vector_storage: this is the storage backend for vector embedding. All configurable parameters for initializing LightRAG instances can be found in the lightrag.py file located at LightRAG/lightrag/lightrag.py.\nWhen you want to perform queries, there are several search modes for you to select under the QueryParam class. Here is an official demo implementation:\ndef main(): # Initialize RAG instance rag = asyncio.run(initialize_rag()) # Insert text rag.insert(\u0026#34;Your text\u0026#34;) # Perform naive search mode=\u0026#34;naive\u0026#34; # Perform local search mode=\u0026#34;local\u0026#34; # Perform global search mode=\u0026#34;global\u0026#34; # Perform hybrid search mode=\u0026#34;hybrid\u0026#34; # Mix mode Integrates knowledge graph and vector retrieval. mode=\u0026#34;mix\u0026#34; rag.query( \u0026#34;What are the top themes in this story?\u0026#34;, param=QueryParam(mode=mode) ) Detailed explanations of these search modes can be found in LightRAG/lightrag/base.py.\nHere’s a breakdown of each mode:\nlocal: Optimized for context-dependent queries that reference specific entities within the knowledge graph. Best for factual questions about details in your documents, like “Who wrote ‘Pride and Prejudice’?” or “What was the revenue in Q4 2024?” global: Leverages broader knowledge to handle abstract or conceptual queries. Ideal for questions requiring synthesis across multiple documents or high-level understanding, such as “How does artificial intelligence influence modern education?” or “What are the main trends in renewable energy?” hybrid: Combines both local and global retrieval methods to provide comprehensive answers. This mode balances specific context with broader knowledge, making it versatile for complex queries that need both detailed and high-level information. naive: Performs a straightforward vector similarity search without advanced retrieval techniques. While simpler and faster, it may miss nuanced relationships in the data. mix: Integrates knowledge graph traversal with vector retrieval, providing the most sophisticated search capability. Additional important query parameters include:\ntop_k: Controls the number of retrieved items. In local mode, this represents the number of entities to retrieve, while in global mode it determines the number of relationships. Default value is 60. stream: When set to true, enables streaming output for real-time responses. This is useful for long-form responses where you want to see results incrementally. Default is false. response_type: Determines the format of the generated response. Available options include: “Multiple Paragraphs”: Returns a detailed response split into multiple paragraphs “Single Paragraph”: Returns a concise response in a single paragraph “Bullet Points”: Returns key points in a bulleted list format Default is “Multiple Paragraphs”. Another important file in the repository is prompt.py.\nThis file defines a collection of prompt templates used in the LightRAG framework. These templates serve as instructions for langauge models to perform various tasks related to knowledge extraction, summarization, and question answering.\nYou may need to change the PROMPTS[\u0026quot;DEFAULT_LANGUAGE]=\u0026quot;English\u0026quot; to adapt your own tasks.\nThere are also many other important components in the official GitHub. The repository also includes detailed documentation and example notebooks that demonstrate how to integrate LightRAG with various LLM providers and vector stores.\nPlease go to check!\n","permalink":"http://localhost:1314/posts/notes-on-lightrag/","summary":"\u003cp\u003eIn this note, I’ll document some critical implementation details about the \u003ccode\u003eLightRAG\u003c/code\u003e framework that I discovered while deploying it in production. These insights, which weren’t immediately apparent from just reading the paper, emerged during my hands-on experience with the codebase and are worth recording for future reference.\u003c/p\u003e","title":"Notes on LightRAG","type":"post"},{"content":"欢迎来到 BubbleBrain 🫧\n这是一个记录技术探索与思考的空间，主要关注以下方向：\n人工智能（AI）与大模型 软件工程与编程实践 产品设计与工程效率 学习与思考的方式论 网站由 Hugo + PaperMod 构建，采用静态托管，加载迅速、可读性优先。你可以在这里：\n浏览我对前沿技术与工程实践的总结 通过分类与搜索快速定位感兴趣的主题 在文章底部使用 Giscus 参与讨论与反馈 更多信息：\n网站: https://bubblebrain.me/ Twitter/X: https://x.com/dylandddeng GitHub: https://github.com/ 感谢你的来到，愿这里的内容能对你有所启发。\n","permalink":"http://localhost:1314/about/","summary":"\u003cp\u003e欢迎来到 BubbleBrain 🫧\u003c/p\u003e\n\u003cp\u003e这是一个记录技术探索与思考的空间，主要关注以下方向：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e人工智能（AI）与大模型\u003c/li\u003e\n\u003cli\u003e软件工程与编程实践\u003c/li\u003e\n\u003cli\u003e产品设计与工程效率\u003c/li\u003e\n\u003cli\u003e学习与思考的方式论\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e网站由 Hugo + PaperMod 构建，采用静态托管，加载迅速、可读性优先。你可以在这里：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e浏览我对前沿技术与工程实践的总结\u003c/li\u003e\n\u003cli\u003e通过分类与搜索快速定位感兴趣的主题\u003c/li\u003e\n\u003cli\u003e在文章底部使用 Giscus 参与讨论与反馈\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e更多信息：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e网站: \u003ca href=\"https://bubblebrain.me/\"\u003ehttps://bubblebrain.me/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eTwitter/X: \u003ca href=\"https://x.com/dylandddeng\"\u003ehttps://x.com/dylandddeng\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eGitHub: \u003ca href=\"https://github.com/\"\u003ehttps://github.com/\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e感谢你的来到，愿这里的内容能对你有所启发。\u003c/p\u003e","title":"关于","type":"post"},{"content":"查看所有带有 Agent 标签的文章","permalink":"http://localhost:1314/tags/agent/","summary":"共 3 篇文章","title":"标签: Agent","type":"tag"},{"content":"查看所有带有 AI 标签的文章","permalink":"http://localhost:1314/tags/ai/","summary":"共 7 篇文章","title":"标签: AI","type":"tag"},{"content":"查看所有带有 Anthropic 标签的文章","permalink":"http://localhost:1314/tags/anthropic/","summary":"共 1 篇文章","title":"标签: Anthropic","type":"tag"},{"content":"查看所有带有 DeepResearch 标签的文章","permalink":"http://localhost:1314/tags/deepresearch/","summary":"共 1 篇文章","title":"标签: DeepResearch","type":"tag"},{"content":"查看所有带有 Kimi 标签的文章","permalink":"http://localhost:1314/tags/kimi/","summary":"共 1 篇文章","title":"标签: Kimi","type":"tag"},{"content":"查看所有带有 LangChain 标签的文章","permalink":"http://localhost:1314/tags/langchain/","summary":"共 1 篇文章","title":"标签: LangChain","type":"tag"},{"content":"查看所有带有 Prompt 标签的文章","permalink":"http://localhost:1314/tags/prompt/","summary":"共 1 篇文章","title":"标签: Prompt","type":"tag"},{"content":"查看所有带有 RAG 标签的文章","permalink":"http://localhost:1314/tags/rag/","summary":"共 1 篇文章","title":"标签: RAG","type":"tag"},{"content":"查看所有带有 Thought 标签的文章","permalink":"http://localhost:1314/tags/thought/","summary":"共 1 篇文章","title":"标签: Thought","type":"tag"},{"content":"查看所有带有 Vibe Coding 标签的文章","permalink":"http://localhost:1314/tags/vibe-coding/","summary":"共 1 篇文章","title":"标签: Vibe Coding","type":"tag"},{"content":"查看所有带有 公众号 标签的文章","permalink":"http://localhost:1314/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/","summary":"共 4 篇文章","title":"标签: 公众号","type":"tag"},{"content":"查看所有带有 多智能体 标签的文章","permalink":"http://localhost:1314/tags/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93/","summary":"共 1 篇文章","title":"标签: 多智能体","type":"tag"},{"content":"查看所有带有 思考 标签的文章","permalink":"http://localhost:1314/tags/%E6%80%9D%E8%80%83/","summary":"共 2 篇文章","title":"标签: 思考","type":"tag"},{"content":"查看所有带有 教程 标签的文章","permalink":"http://localhost:1314/tags/%E6%95%99%E7%A8%8B/","summary":"共 1 篇文章","title":"标签: 教程","type":"tag"},{"content":"查看所有带有 测试 标签的文章","permalink":"http://localhost:1314/tags/%E6%B5%8B%E8%AF%95/","summary":"共 1 篇文章","title":"标签: 测试","type":"tag"},{"content":"查看所有带有 灵感 标签的文章","permalink":"http://localhost:1314/tags/%E7%81%B5%E6%84%9F/","summary":"共 2 篇文章","title":"标签: 灵感","type":"tag"},{"content":"查看所有带有 碎碎念 标签的文章","permalink":"http://localhost:1314/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/","summary":"共 1 篇文章","title":"标签: 碎碎念","type":"tag"},{"content":"查看所有带有 移动端 标签的文章","permalink":"http://localhost:1314/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF/","summary":"共 1 篇文章","title":"标签: 移动端","type":"tag"},{"content":"查看所有带有 视频 标签的文章","permalink":"http://localhost:1314/tags/%E8%A7%86%E9%A2%91/","summary":"共 1 篇文章","title":"标签: 视频","type":"tag"},{"content":"查看所有带有 访谈 标签的文章","permalink":"http://localhost:1314/tags/%E8%AE%BF%E8%B0%88/","summary":"共 2 篇文章","title":"标签: 访谈","type":"tag"}]